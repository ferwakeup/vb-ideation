{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Business Idea Generation - Production Ready\n",
    "\n",
    "This notebook demonstrates a **production-ready** multi-agent system for business idea generation with:\n",
    "- **Provider-Agnostic**: Works with Ollama, Groq, Anthropic, or OpenAI\n",
    "- **Checkpoint System**: Save/resume from any point (no re-processing!)\n",
    "- **High-Quality PDF Extraction**: Uses PyMuPDF for superior text extraction\n",
    "\n",
    "## What This Does:\n",
    "1. **Agent 1**: Extract key information from PDF (with checkpoint save)\n",
    "2. **Agent 2**: Generate business ideas (resumes from Agent 1 checkpoint)\n",
    "3. **Agent 3**: 11 specialized dimensional evaluations (each with checkpoint save)\n",
    "4. **Agent 4**: 3 specialized synthesis sub-agents (4.1: summary, 4.2: strengths, 4.3: concerns)\n",
    "5. **Agent 5**: Final consolidation and JSON report generation\n",
    "\n",
    "## Key Features:\n",
    "- âœ… **4 LLM Providers**: Ollama (local), Groq (free), Anthropic, OpenAI\n",
    "- âœ… **Smart Checkpointing**: Resume from any agent, skip completed work\n",
    "- âœ… **PyMuPDF Extraction**: Faster and more accurate than PyPDF\n",
    "- âœ… **Technical Prompts**: Professional agent design patterns\n",
    "- âœ… **Noise Filtering**: Agent 1 eliminates irrelevant information\n",
    "- âœ… **11-Dimension Evaluation**: Comprehensive business idea scoring\n",
    "- âœ… **Modular Synthesis**: Separate agents for summary, strengths, and concerns\n",
    "- âœ… **Weighted Scoring**: Configurable importance per dimension\n",
    "- âœ… **JSON Output**: Structured final report with recommendations\n",
    "\n",
    "## Provider Options:\n",
    "\n",
    "### ğŸ†“ **Groq** (RECOMMENDED for Experimentation)\n",
    "- **Speed**: 1-2 seconds per request âš¡\n",
    "- **Cost**: FREE (generous limits)\n",
    "- **Quality**: Excellent (Llama 3.3 70B)\n",
    "- **Setup**: Get API key at https://console.groq.com\n",
    "\n",
    "### ğŸ’» **Ollama** (Local/Private)\n",
    "- **Speed**: Varies by hardware (CPU: 1-2 min, GPU: 5-15 sec)\n",
    "- **Cost**: FREE (requires local install)\n",
    "- **Privacy**: 100% local, no data leaves your machine\n",
    "\n",
    "### ğŸš€ **Anthropic Claude** (Production)\n",
    "- **Speed**: 2-3 seconds âš¡\n",
    "- **Cost**: ~$0.75 per 250K document\n",
    "- **Quality**: Best for business analysis\n",
    "- **Context**: Handles 800K characters in single pass\n",
    "\n",
    "### ğŸ¤– **OpenAI GPT** (Alternative Production)\n",
    "- **Speed**: 2-3 seconds âš¡\n",
    "- **Cost**: ~$0.62 per 250K document\n",
    "- **Quality**: Excellent\n",
    "- **Context**: 512K characters\n",
    "\n",
    "## Requirements:\n",
    "- **For Ollama**: Ollama installed with a model\n",
    "- **For Groq**: Free API key (https://console.groq.com)\n",
    "- **For Anthropic**: API key\n",
    "- **For OpenAI**: API key\n",
    "- PDF file in the `data/` folder\n",
    "\n",
    "## Quick Start:\n",
    "\n",
    "**Development/Testing (FREE):**\n",
    "```python\n",
    "PROVIDER = \"groq\"  # Free, 1-2 seconds per request\n",
    "```\n",
    "\n",
    "**Production (BEST QUALITY):**\n",
    "```python\n",
    "PROVIDER = \"anthropic\"  # Claude Sonnet, ~$0.75 per 250K doc\n",
    "```\n",
    "\n",
    "**Local/Private:**\n",
    "```python\n",
    "PROVIDER = \"ollama\"  # Free, local, private\n",
    "```\n",
    "\n",
    "## Checkpoint System:\n",
    "\n",
    "Checkpoints auto-save after each agent. To resume:\n",
    "1. Run notebook normally - automatically loads checkpoints\n",
    "2. To force fresh run: Set `USE_CHECKPOINTS = False`\n",
    "3. To clear checkpoints: Use checkpoint management cells\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Run this cell only once\n",
    "# !pip install langchain langchain-ollama langchain-anthropic langchain-openai langchain-groq pymupdf python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Libraries imported successfully\n",
      "âœ“ Environment variables loaded from .env file (if present)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Optional\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import getpass\n",
    "\n",
    "# Load environment variables from .env file (if it exists)\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ“ Libraries imported successfully\")\n",
    "print(\"âœ“ Environment variables loaded from .env file (if present)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration\n",
    "\n",
    "**ğŸ” Secure Key Management:**\n",
    "\n",
    "This notebook uses **3 secure methods** to handle API keys (no keys in notebook):\n",
    "\n",
    "1. **Environment Variables** (Windows/Linux/Mac)\n",
    "2. **.env File** (Recommended - see instructions below) â­\n",
    "3. **Manual Entry** (Interactive prompt if no key found)\n",
    "\n",
    "**Your keys are NEVER saved in the notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configuration:\n",
      "  Provider: ANTHROPIC\n",
      "  PDF: data/EITUM_MDS-study_long (3).pdf\n",
      "  Sector: mobility\n",
      "  Ideas to generate: 3\n",
      "  Checkpoints: Enabled\n",
      "  Per-agent control: Agent1=True, Agent2=True, Agent3=True\n",
      "  Model: claude-3-haiku-20240307\n",
      "  API Key: âœ“ Loaded securely\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ğŸ” SECURE API KEY MANAGEMENT\n",
    "# ============================================================================\n",
    "\n",
    "def get_api_key(key_name: str, provider_name: str, required: bool = False) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Securely retrieve API key using multiple methods (never stored in notebook).\n",
    "    \n",
    "    Priority order:\n",
    "    1. Environment variable\n",
    "    2. .env file (auto-loaded)\n",
    "    3. Manual entry (interactive prompt)\n",
    "    \n",
    "    Args:\n",
    "        key_name: Environment variable name (e.g., \"GROQ_API_KEY\")\n",
    "        provider_name: Human-readable provider name (e.g., \"Groq\")\n",
    "        required: If True, prompts for manual entry if not found\n",
    "        \n",
    "    Returns:\n",
    "        API key string or None\n",
    "    \"\"\"\n",
    "    # Try to get from environment (includes .env file)\n",
    "    api_key = os.getenv(key_name)\n",
    "    \n",
    "    if api_key:\n",
    "        return api_key\n",
    "    \n",
    "    # If required and not found, prompt user\n",
    "    if required:\n",
    "        print(f\"\\nğŸ”‘ {provider_name} API key not found in environment variables or .env file\")\n",
    "        print(f\"   Please enter your {provider_name} API key (input hidden for security):\")\n",
    "        api_key = getpass.getpass(f\"   {provider_name} API Key: \")\n",
    "        \n",
    "        if api_key:\n",
    "            # Optionally save to environment for this session only\n",
    "            os.environ[key_name] = api_key\n",
    "            print(f\"   âœ“ API key set for this session (not saved to notebook)\")\n",
    "            return api_key\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION - CHANGE PROVIDER HERE TO SWITCH BETWEEN LLM PROVIDERS\n",
    "# ============================================================================\n",
    "\n",
    "# Provider Selection: \"ollama\", \"anthropic\", \"openai\", or \"groq\"\n",
    "PROVIDER = \"anthropic\"\n",
    "\n",
    "# Document Configuration\n",
    "PDF_PATH = \"data/EITUM_MDS-study_long (3).pdf\"  # Path to your PDF\n",
    "SECTOR = \"mobility\"  # Sector to analyze\n",
    "NUM_IDEAS = 3  # Number of ideas to generate\n",
    "\n",
    "# ============================================================================\n",
    "# CHECKPOINT CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "USE_CHECKPOINTS = True  # Master switch: False = ignore all checkpoints\n",
    "\n",
    "# Per-agent control: Set to False to force re-running specific agents\n",
    "USE_CHECKPOINT_AGENT1 = True   # Set False to force Agent 1 re-run\n",
    "USE_CHECKPOINT_AGENT2 = True   # Set False to force Agent 2 re-run\n",
    "USE_CHECKPOINT_AGENT3 = True   # Set False to force Agent 3 re-run\n",
    "\n",
    "# ============================================================================\n",
    "# PROVIDER-SPECIFIC CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# --- OLLAMA Configuration ---\n",
    "OLLAMA_CONFIG = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"base_url\": \"http://localhost:11434\",\n",
    "    \"keep_alive\": \"10m\"  # Keep model loaded in memory for 10 minutes\n",
    "}\n",
    "\n",
    "# --- GROQ Configuration (FREE, VERY FAST) ---\n",
    "# ğŸ” Secure: API key loaded from environment or .env file\n",
    "# Current models (as of Jan 2025): https://console.groq.com/docs/models\n",
    "GROQ_CONFIG = {\n",
    "    \"model\": \"llama-3.3-70b-versatile\",  # Latest Llama 3.3 (recommended)\n",
    "    # Alternative models:\n",
    "    # \"llama-3.3-70b-versatile\",  # Latest Llama 3.3 (recommended)\n",
    "    # \"llama-3.1-8b-instant\" - Faster, lighter (good for testing)\n",
    "    # \"mixtral-8x7b-32768\" - Good for long context\n",
    "    # \"gemma2-9b-it\" - Google's Gemma model\n",
    "    \"api_key\": None  # Will be loaded securely when needed\n",
    "}\n",
    "\n",
    "# --- ANTHROPIC Configuration ---\n",
    "# ğŸ” Secure: API key loaded from environment or .env file\n",
    "ANTHROPIC_CONFIG = {\n",
    "    \"model\": \"claude-3-haiku-20240307\",\n",
    "    # Choose model from:\n",
    "    # \"claude-sonnet-4-5-20250514\" - Sonnet 4.5 - Best reasoning & analysis (10x cost of Haiku)\n",
    "    # \"claude-3-haiku-20240307\" - Haiku 3.5 - Fast & cost-effective (recommended for structured tasks)\n",
    "    \"api_key\": None  # Will be loaded securely when needed\n",
    "}\n",
    "\n",
    "# --- OPENAI Configuration ---\n",
    "# ğŸ” Secure: API key loaded from environment or .env file\n",
    "OPENAI_CONFIG = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"api_key\": None  # Will be loaded securely when needed\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "# LOAD API KEYS SECURELY (when provider is selected)\n",
    "# ============================================================================\n",
    "\n",
    "# Only load the key for the selected provider\n",
    "if PROVIDER == \"groq\":\n",
    "    GROQ_CONFIG[\"api_key\"] = get_api_key(\"GROQ_API_KEY\", \"Groq\", required=True)\n",
    "elif PROVIDER == \"anthropic\":\n",
    "    ANTHROPIC_CONFIG[\"api_key\"] = get_api_key(\"ANTHROPIC_API_KEY\", \"Anthropic\", required=True)\n",
    "elif PROVIDER == \"openai\":\n",
    "    OPENAI_CONFIG[\"api_key\"] = get_api_key(\"OPENAI_API_KEY\", \"OpenAI\", required=True)\n",
    "\n",
    "# ============================================================================\n",
    "# DISPLAY CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Provider: {PROVIDER.upper()}\")\n",
    "print(f\"  PDF: {PDF_PATH}\")\n",
    "print(f\"  Sector: {SECTOR}\")\n",
    "print(f\"  Ideas to generate: {NUM_IDEAS}\")\n",
    "print(f\"  Checkpoints: {'Enabled' if USE_CHECKPOINTS else 'Disabled'}\")\n",
    "print(f\"  Per-agent control: Agent1={USE_CHECKPOINT_AGENT1}, Agent2={USE_CHECKPOINT_AGENT2}, Agent3={USE_CHECKPOINT_AGENT3}\")\n",
    "\n",
    "if PROVIDER == \"ollama\":\n",
    "    print(f\"  Model: {OLLAMA_CONFIG['model']}\")\n",
    "    print(f\"  Base URL: {OLLAMA_CONFIG['base_url']}\")\n",
    "    print(f\"  Keep-Alive: {OLLAMA_CONFIG['keep_alive']}\")\n",
    "elif PROVIDER == \"groq\":\n",
    "    print(f\"  Model: {GROQ_CONFIG['model']}\")\n",
    "    print(f\"  API Key: {'âœ“ Loaded securely' if GROQ_CONFIG['api_key'] else 'âœ— Not found'}\")\n",
    "elif PROVIDER == \"anthropic\":\n",
    "    print(f\"  Model: {ANTHROPIC_CONFIG['model']}\")\n",
    "    print(f\"  API Key: {'âœ“ Loaded securely' if ANTHROPIC_CONFIG['api_key'] else 'âœ— Not found'}\")\n",
    "elif PROVIDER == \"openai\":\n",
    "    print(f\"  Model: {OPENAI_CONFIG['model']}\")\n",
    "    print(f\"  API Key: {'âœ“ Loaded securely' if OPENAI_CONFIG['api_key'] else 'âœ— Not found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ” How to Set Up Secure API Keys (.env file)\n",
    "\n",
    "**Recommended Method:** Use a `.env` file to store your API keys securely.\n",
    "\n",
    "### Step 1: Create .env File\n",
    "\n",
    "In the same folder as this notebook, create a file named `.env` (no extension):\n",
    "\n",
    "```bash\n",
    "# File: .env\n",
    "# This file stores your API keys (never commit to git!)\n",
    "\n",
    "# Groq API Key (free at https://console.groq.com)\n",
    "GROQ_API_KEY=gsk_your_groq_api_key_here\n",
    "\n",
    "# Anthropic API Key (https://console.anthropic.com)\n",
    "ANTHROPIC_API_KEY=sk-ant-your_anthropic_key_here\n",
    "\n",
    "# OpenAI API Key (https://platform.openai.com)\n",
    "OPENAI_API_KEY=sk-your_openai_key_here\n",
    "```\n",
    "\n",
    "### Step 2: Create .gitignore File\n",
    "\n",
    "**IMPORTANT:** Prevent accidentally sharing your keys!\n",
    "\n",
    "Create a file named `.gitignore` in the same folder:\n",
    "\n",
    "```bash\n",
    "# File: .gitignore\n",
    "# Prevents sensitive files from being committed to git\n",
    "\n",
    "# API Keys\n",
    ".env\n",
    "\n",
    "# Checkpoints (optional - can contain proprietary data)\n",
    "checkpoints/\n",
    "\n",
    "# Results\n",
    "results_*.json\n",
    "\n",
    "# Python\n",
    "__pycache__/\n",
    "*.pyc\n",
    ".ipynb_checkpoints/\n",
    "```\n",
    "\n",
    "### Step 3: Verify\n",
    "\n",
    "Run the configuration cell above. You should see:\n",
    "```\n",
    "âœ“ Environment variables loaded from .env file (if present)\n",
    "Configuration:\n",
    "  Provider: GROQ\n",
    "  API Key: âœ“ Loaded securely\n",
    "```\n",
    "\n",
    "### Alternative Methods:\n",
    "\n",
    "**Method 2: System Environment Variables**\n",
    "\n",
    "**Windows:**\n",
    "```cmd\n",
    "set GROQ_API_KEY=your_key_here\n",
    "```\n",
    "\n",
    "**Mac/Linux:**\n",
    "```bash\n",
    "export GROQ_API_KEY=your_key_here\n",
    "```\n",
    "\n",
    "**Method 3: Manual Entry**\n",
    "\n",
    "If no key is found, the notebook will prompt you to enter it securely (input is hidden).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ Your Folder Structure:\n",
    "\n",
    "```\n",
    "C:\\Users\\nekov\\Desktop\\Test Ollama\\basic_test_jupyter_notebook\\\n",
    "â”œâ”€â”€ simple_multiagent_test.ipynb  â† This notebook\n",
    "â”œâ”€â”€ .env                           â† Your API keys (never shared!)\n",
    "â”œâ”€â”€ .gitignore                     â† Git safety config\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â””â”€â”€ sample_mobility_report.pdf\n",
    "â””â”€â”€ checkpoints/\n",
    "    â””â”€â”€ agent1_*.json\n",
    "```\n",
    "\n",
    "**Safe to share:** `simple_multiagent_test.ipynb`\n",
    "**NEVER share:** `.env` file (contains your keys!)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ LLM Factory Function & Checkpoint System\n",
    "\n",
    "**Purpose**: \n",
    "- Create the appropriate LLM instance based on provider configuration\n",
    "- Manage checkpoint saving/loading for all agents\n",
    "\n",
    "This allows seamless switching between providers and resuming from saved checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ LLM factory function defined\n",
      "âœ“ Checkpoint system initialized\n",
      "âœ“ Ready to use ANTHROPIC provider with model: claude-3-haiku-20240307\n",
      "\n",
      "ğŸ“‹ Checkpoint Features:\n",
      "  â€¢ Timestamped auto-save (preserves version history)\n",
      "  â€¢ Auto-loads latest checkpoint\n",
      "  â€¢ Per-agent control (USE_CHECKPOINT_AGENT1/2/3)\n",
      "  â€¢ Supports 17 agents: agent1, agent2, agent3_1..agent3_11, agent4_1..agent4_3, agent5\n",
      "  â€¢ PDF-specific checkpoints (unique per document)\n",
      "  â€¢ New PDF detection (automatic full pipeline trigger)\n",
      "  â€¢ cleanup_old_checkpoints() utility\n",
      "\n",
      "================================================================================\n",
      "CHECKPOINT STATUS FOR CURRENT PDF\n",
      "================================================================================\n",
      "PDF: EITUM_MDS-study_long (3)\n",
      "Sector: mobility\n",
      "Full path: data/EITUM_MDS-study_long (3).pdf\n",
      "\n",
      "ğŸ†• NEW ANALYSIS DETECTED\n",
      "   No checkpoints found for this PDF/sector combination.\n",
      "   All 17 agents will execute to generate complete analysis.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# LLM FACTORY FUNCTION & IMPROVED CHECKPOINT MANAGEMENT\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_llm(temperature: float = 0.5):\n",
    "    \"\"\"\n",
    "    Factory function to create appropriate LLM instance based on provider configuration.\n",
    "    \n",
    "    Args:\n",
    "        temperature (float): Temperature setting for the LLM (0.0-1.0)\n",
    "                           Lower = more focused, Higher = more creative\n",
    "    \n",
    "    Returns:\n",
    "        LLM instance (ChatOllama, ChatGroq, ChatAnthropic, or ChatOpenAI)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If provider is not supported or configuration is invalid\n",
    "    \"\"\"\n",
    "    \n",
    "    if PROVIDER == \"ollama\":\n",
    "        # Build kwargs for ChatOllama\n",
    "        ollama_kwargs = {\n",
    "            \"model\": OLLAMA_CONFIG[\"model\"],\n",
    "            \"base_url\": OLLAMA_CONFIG[\"base_url\"],\n",
    "            \"temperature\": temperature\n",
    "        }\n",
    "        \n",
    "        # Add keep_alive if specified\n",
    "        if \"keep_alive\" in OLLAMA_CONFIG:\n",
    "            ollama_kwargs[\"keep_alive\"] = OLLAMA_CONFIG[\"keep_alive\"]\n",
    "        \n",
    "        return ChatOllama(**ollama_kwargs)\n",
    "    \n",
    "    elif PROVIDER == \"groq\":\n",
    "        if not GROQ_CONFIG[\"api_key\"]:\n",
    "            raise ValueError(\n",
    "                \"Groq API key not set. Set GROQ_API_KEY environment variable \"\n",
    "                \"or update GROQ_CONFIG['api_key'] in configuration cell.\\n\"\n",
    "                \"Get free API key at: https://console.groq.com\"\n",
    "            )\n",
    "        return ChatGroq(\n",
    "            model=GROQ_CONFIG[\"model\"],\n",
    "            api_key=GROQ_CONFIG[\"api_key\"],\n",
    "            temperature=temperature\n",
    "        )\n",
    "    \n",
    "    elif PROVIDER == \"anthropic\":\n",
    "        if not ANTHROPIC_CONFIG[\"api_key\"]:\n",
    "            raise ValueError(\n",
    "                \"Anthropic API key not set. Set ANTHROPIC_API_KEY environment variable \"\n",
    "                \"or update ANTHROPIC_CONFIG['api_key'] in configuration cell.\"\n",
    "            )\n",
    "        return ChatAnthropic(\n",
    "            model=ANTHROPIC_CONFIG[\"model\"],\n",
    "            api_key=ANTHROPIC_CONFIG[\"api_key\"],\n",
    "            temperature=temperature\n",
    "        )\n",
    "    \n",
    "    elif PROVIDER == \"openai\":\n",
    "        if not OPENAI_CONFIG[\"api_key\"]:\n",
    "            raise ValueError(\n",
    "                \"OpenAI API key not set. Set OPENAI_API_KEY environment variable \"\n",
    "                \"or update OPENAI_CONFIG['api_key'] in configuration cell.\"\n",
    "            )\n",
    "        return ChatOpenAI(\n",
    "            model=OPENAI_CONFIG[\"model\"],\n",
    "            api_key=OPENAI_CONFIG[\"api_key\"],\n",
    "            temperature=temperature\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unsupported provider: {PROVIDER}. \"\n",
    "            f\"Choose from: 'ollama', 'groq', 'anthropic', or 'openai'\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# IMPROVED CHECKPOINT MANAGEMENT FUNCTIONS (Timestamped + Per-Agent Control)\n",
    "# ============================================================================\n",
    "\n",
    "def get_checkpoint_path(agent_name: str, pdf_path: str, sector: str) -> Path:\n",
    "    \"\"\"\n",
    "    Generate TIMESTAMPED checkpoint file path for an agent.\n",
    "    \n",
    "    Args:\n",
    "        agent_name: Name of the agent (e.g., 'agent1', 'agent2', 'agent3_1', 'agent4_1', 'agent5')\n",
    "        pdf_path: Path to the PDF being processed\n",
    "        sector: Sector being analyzed\n",
    "        \n",
    "    Returns:\n",
    "        Path to timestamped checkpoint file\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    checkpoint_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    pdf_name = Path(pdf_path).stem\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    filename = f\"{agent_name}_{pdf_name}_{sector}_{timestamp}.json\"\n",
    "    \n",
    "    return checkpoint_dir / filename\n",
    "\n",
    "\n",
    "def find_latest_checkpoint(agent_name: str, pdf_path: str, sector: str) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Find the most recent checkpoint for a given agent/PDF/sector combination.\n",
    "    \n",
    "    Args:\n",
    "        agent_name: Name of the agent\n",
    "        pdf_path: Path to the PDF being processed\n",
    "        sector: Sector being analyzed\n",
    "        \n",
    "    Returns:\n",
    "        Path to the latest checkpoint file or None if no checkpoints exist\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        return None\n",
    "    \n",
    "    # Find all matching checkpoints\n",
    "    pdf_name = Path(pdf_path).stem\n",
    "    pattern = f\"{agent_name}_{pdf_name}_{sector}_*.json\"\n",
    "    matching_files = list(checkpoint_dir.glob(pattern))\n",
    "    \n",
    "    if not matching_files:\n",
    "        return None\n",
    "    \n",
    "    # Return the most recently modified file\n",
    "    latest = max(matching_files, key=lambda p: p.stat().st_mtime)\n",
    "    return latest\n",
    "\n",
    "\n",
    "def count_checkpoints_for_current_pdf() -> Dict[str, int]:\n",
    "    \"\"\"\n",
    "    Count how many checkpoints exist for the current PDF/sector combination.\n",
    "    \n",
    "    Returns:\n",
    "        Dict with checkpoint counts per agent\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        return {}\n",
    "    \n",
    "    pdf_name = Path(PDF_PATH).stem\n",
    "    all_agents = (\n",
    "        [\"agent1\", \"agent2\"] + \n",
    "        [f\"agent3_{i}\" for i in range(1, 12)] + \n",
    "        [f\"agent4_{i}\" for i in range(1, 4)] + \n",
    "        [\"agent5\"]\n",
    "    )\n",
    "    \n",
    "    counts = {}\n",
    "    for agent in all_agents:\n",
    "        pattern = f\"{agent}_{pdf_name}_{SECTOR}_*.json\"\n",
    "        matching_files = list(checkpoint_dir.glob(pattern))\n",
    "        counts[agent] = len(matching_files)\n",
    "    \n",
    "    return counts\n",
    "\n",
    "\n",
    "def is_new_pdf_analysis() -> bool:\n",
    "    \"\"\"\n",
    "    Check if this is a new PDF analysis (no checkpoints exist for current PDF/sector).\n",
    "    \n",
    "    Returns:\n",
    "        True if no checkpoints exist for the current PDF, False otherwise\n",
    "    \"\"\"\n",
    "    counts = count_checkpoints_for_current_pdf()\n",
    "    return sum(counts.values()) == 0\n",
    "\n",
    "\n",
    "def save_checkpoint(agent_name: str, data: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Save agent output to TIMESTAMPED checkpoint file.\n",
    "    \n",
    "    Args:\n",
    "        agent_name: Name of the agent (e.g., 'agent1', 'agent2', 'agent3_1', 'agent4_1', 'agent5')\n",
    "        data: Data to save\n",
    "    \"\"\"\n",
    "    checkpoint_path = get_checkpoint_path(agent_name, PDF_PATH, SECTOR)\n",
    "    \n",
    "    checkpoint_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"provider\": PROVIDER,\n",
    "        \"model\": (\n",
    "            OLLAMA_CONFIG[\"model\"] if PROVIDER == \"ollama\" \n",
    "            else GROQ_CONFIG[\"model\"] if PROVIDER == \"groq\"\n",
    "            else ANTHROPIC_CONFIG[\"model\"] if PROVIDER == \"anthropic\" \n",
    "            else OPENAI_CONFIG[\"model\"]\n",
    "        ),\n",
    "        \"pdf_path\": PDF_PATH,\n",
    "        \"sector\": SECTOR,\n",
    "        \"data\": data\n",
    "    }\n",
    "    \n",
    "    with open(checkpoint_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"ğŸ’¾ Checkpoint saved: {checkpoint_path.name}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(agent_name: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Load the LATEST checkpoint for an agent (with per-agent control).\n",
    "    \n",
    "    Args:\n",
    "        agent_name: Name of the agent (e.g., 'agent1', 'agent2', 'agent3_1', 'agent4_1', 'agent5')\n",
    "        \n",
    "    Returns:\n",
    "        Loaded data or None if checkpoint doesn't exist or should be skipped\n",
    "    \"\"\"\n",
    "    # Check global flag\n",
    "    if not USE_CHECKPOINTS:\n",
    "        return None\n",
    "    \n",
    "    # Check per-agent flags (for main agents)\n",
    "    agent_flags = {\n",
    "        \"agent1\": USE_CHECKPOINT_AGENT1,\n",
    "        \"agent2\": USE_CHECKPOINT_AGENT2,\n",
    "        \"agent3\": USE_CHECKPOINT_AGENT3\n",
    "    }\n",
    "    \n",
    "    # For agent3_X sub-agents, use agent3 flag\n",
    "    if agent_name.startswith(\"agent3_\"):\n",
    "        if not agent_flags.get(\"agent3\", True):\n",
    "            print(f\"â„¹ï¸  Checkpoint disabled for {agent_name} (agent3 flag is False)\")\n",
    "            return None\n",
    "    elif agent_name in agent_flags and not agent_flags[agent_name]:\n",
    "        print(f\"â„¹ï¸  Checkpoint disabled for {agent_name} (forcing re-run)\")\n",
    "        return None\n",
    "    \n",
    "    # Find the latest checkpoint\n",
    "    checkpoint_path = find_latest_checkpoint(agent_name, PDF_PATH, SECTOR)\n",
    "    \n",
    "    if checkpoint_path is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(checkpoint_path, 'r', encoding='utf-8') as f:\n",
    "            checkpoint_data = json.load(f)\n",
    "        \n",
    "        timestamp = checkpoint_data.get(\"timestamp\", \"unknown\")\n",
    "        provider = checkpoint_data.get(\"provider\", \"unknown\")\n",
    "        model = checkpoint_data.get(\"model\", \"unknown\")\n",
    "        \n",
    "        print(f\"ğŸ“‚ Loading latest checkpoint: {checkpoint_path.name}\")\n",
    "        print(f\"   Timestamp: {timestamp}\")\n",
    "        print(f\"   Provider: {provider} ({model})\")\n",
    "        \n",
    "        return checkpoint_data[\"data\"]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Failed to load checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def list_checkpoints() -> None:\n",
    "    \"\"\"List all available checkpoints grouped by agent.\"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        print(\"No checkpoints directory found.\")\n",
    "        return\n",
    "    \n",
    "    checkpoints = list(checkpoint_dir.glob(\"*.json\"))\n",
    "    \n",
    "    if not checkpoints:\n",
    "        print(\"No checkpoints found.\")\n",
    "        return\n",
    "    \n",
    "    # Group by agent\n",
    "    grouped = defaultdict(list)\n",
    "    \n",
    "    for cp in sorted(checkpoints):\n",
    "        # Extract agent name (handles agent3_1, agent4_1, etc.)\n",
    "        parts = cp.name.split('_')\n",
    "        if parts[0] in [\"agent3\", \"agent4\"] and len(parts) > 1 and parts[1].isdigit():\n",
    "            agent = f\"{parts[0]}_{parts[1]}\"\n",
    "        else:\n",
    "            agent = parts[0]\n",
    "        grouped[agent].append(cp)\n",
    "    \n",
    "    print(f\"\\nğŸ“ Available checkpoints ({len(checkpoints)} total):\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for agent in sorted(grouped.keys()):\n",
    "        print(f\"\\n{agent.upper()}:\")\n",
    "        for cp in sorted(grouped[agent], key=lambda p: p.stat().st_mtime, reverse=True):\n",
    "            try:\n",
    "                with open(cp, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                timestamp = data.get(\"timestamp\", \"unknown\")\n",
    "                provider = data.get(\"provider\", \"unknown\")\n",
    "                model = data.get(\"model\", \"unknown\")\n",
    "                \n",
    "                # Mark the latest one\n",
    "                latest = cp == find_latest_checkpoint(agent, PDF_PATH, SECTOR)\n",
    "                marker = \" â† LATEST\" if latest else \"\"\n",
    "                \n",
    "                print(f\"  {cp.name}{marker}\")\n",
    "                print(f\"    Timestamp: {timestamp}\")\n",
    "                print(f\"    Provider: {provider} ({model})\")\n",
    "                print()\n",
    "            except:\n",
    "                print(f\"  {cp.name} (corrupted)\")\n",
    "                print()\n",
    "\n",
    "\n",
    "def show_current_pdf_status() -> None:\n",
    "    \"\"\"\n",
    "    Display checkpoint status for the current PDF/sector combination.\n",
    "    Shows whether this is a new analysis or continuation.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CHECKPOINT STATUS FOR CURRENT PDF\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    pdf_name = Path(PDF_PATH).stem\n",
    "    print(f\"PDF: {pdf_name}\")\n",
    "    print(f\"Sector: {SECTOR}\")\n",
    "    print(f\"Full path: {PDF_PATH}\")\n",
    "    \n",
    "    counts = count_checkpoints_for_current_pdf()\n",
    "    total_checkpoints = sum(counts.values())\n",
    "    \n",
    "    if total_checkpoints == 0:\n",
    "        print(f\"\\nğŸ†• NEW ANALYSIS DETECTED\")\n",
    "        print(f\"   No checkpoints found for this PDF/sector combination.\")\n",
    "        print(f\"   All 17 agents will execute to generate complete analysis.\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ“‚ EXISTING CHECKPOINTS FOUND: {total_checkpoints} total\")\n",
    "        print(f\"\\nCheckpoint breakdown:\")\n",
    "        \n",
    "        # Agent 1\n",
    "        if counts.get(\"agent1\", 0) > 0:\n",
    "            print(f\"  âœ“ Agent 1 (Extraction): {counts['agent1']} checkpoint(s)\")\n",
    "        else:\n",
    "            print(f\"  âœ— Agent 1 (Extraction): No checkpoints\")\n",
    "        \n",
    "        # Agent 2\n",
    "        if counts.get(\"agent2\", 0) > 0:\n",
    "            print(f\"  âœ“ Agent 2 (Idea Generation): {counts['agent2']} checkpoint(s)\")\n",
    "        else:\n",
    "            print(f\"  âœ— Agent 2 (Idea Generation): No checkpoints\")\n",
    "        \n",
    "        # Agent 3 (11 sub-agents)\n",
    "        agent3_count = sum(counts.get(f\"agent3_{i}\", 0) for i in range(1, 12))\n",
    "        if agent3_count == 11:\n",
    "            print(f\"  âœ“ Agent 3 (Dimensional Evaluations): All 11 sub-agents complete\")\n",
    "        elif agent3_count > 0:\n",
    "            print(f\"  âš ï¸  Agent 3 (Dimensional Evaluations): {agent3_count}/11 sub-agents complete\")\n",
    "        else:\n",
    "            print(f\"  âœ— Agent 3 (Dimensional Evaluations): No checkpoints\")\n",
    "        \n",
    "        # Agent 4 (3 sub-agents)\n",
    "        agent4_count = sum(counts.get(f\"agent4_{i}\", 0) for i in range(1, 4))\n",
    "        if agent4_count == 3:\n",
    "            print(f\"  âœ“ Agent 4 (Synthesis Sub-agents): All 3 sub-agents complete\")\n",
    "        elif agent4_count > 0:\n",
    "            print(f\"  âš ï¸  Agent 4 (Synthesis Sub-agents): {agent4_count}/3 sub-agents complete\")\n",
    "        else:\n",
    "            print(f\"  âœ— Agent 4 (Synthesis Sub-agents): No checkpoints\")\n",
    "        \n",
    "        # Agent 5\n",
    "        if counts.get(\"agent5\", 0) > 0:\n",
    "            print(f\"  âœ“ Agent 5 (Final Consolidation): {counts['agent5']} checkpoint(s)\")\n",
    "        else:\n",
    "            print(f\"  âœ— Agent 5 (Final Consolidation): No checkpoints\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¡ Agents with checkpoints will be skipped (unless disabled in config)\")\n",
    "        print(f\"   To force re-run: Set USE_CHECKPOINTS = False or use per-agent flags\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "def cleanup_old_checkpoints(agent_name: str = \"all\", keep_latest: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Delete old checkpoints, keeping only the N most recent ones.\n",
    "    \n",
    "    Args:\n",
    "        agent_name: Name of the agent (or \"all\" for all agents)\n",
    "        keep_latest: Number of recent checkpoints to keep (default: 3)\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        print(\"No checkpoints directory found.\")\n",
    "        return\n",
    "    \n",
    "    if agent_name == \"all\":\n",
    "        # Include all agents: agent1, agent2, agent3_1..agent3_11, agent4_1..agent4_3, agent5\n",
    "        agents = (\n",
    "            [\"agent1\", \"agent2\"] + \n",
    "            [f\"agent3_{i}\" for i in range(1, 12)] + \n",
    "            [f\"agent4_{i}\" for i in range(1, 4)] + \n",
    "            [\"agent5\"]\n",
    "        )\n",
    "    else:\n",
    "        agents = [agent_name]\n",
    "    \n",
    "    total_deleted = 0\n",
    "    \n",
    "    for agent in agents:\n",
    "        # Find all checkpoints for this agent\n",
    "        pdf_name = Path(PDF_PATH).stem\n",
    "        pattern = f\"{agent}_{pdf_name}_{SECTOR}_*.json\"\n",
    "        matching_files = sorted(\n",
    "            checkpoint_dir.glob(pattern),\n",
    "            key=lambda p: p.stat().st_mtime,\n",
    "            reverse=True  # Most recent first\n",
    "        )\n",
    "        \n",
    "        # Delete all except the N most recent\n",
    "        to_delete = matching_files[keep_latest:]\n",
    "        \n",
    "        for cp in to_delete:\n",
    "            cp.unlink()\n",
    "            print(f\"ğŸ—‘ï¸  Deleted: {cp.name}\")\n",
    "            total_deleted += 1\n",
    "    \n",
    "    if total_deleted == 0:\n",
    "        print(\"âœ“ No old checkpoints to delete\")\n",
    "    else:\n",
    "        print(f\"\\nâœ“ Deleted {total_deleted} old checkpoint(s)\")\n",
    "\n",
    "\n",
    "def clear_checkpoints_for_pdf(pdf_path: str, sector: str) -> None:\n",
    "    \"\"\"\n",
    "    Delete ALL checkpoints for a specific PDF/sector combination.\n",
    "    Use this when starting fresh analysis of a document.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        sector: Sector name\n",
    "    \"\"\"\n",
    "    checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        print(\"No checkpoints directory found.\")\n",
    "        return\n",
    "    \n",
    "    pdf_name = Path(pdf_path).stem\n",
    "    pattern = f\"*_{pdf_name}_{sector}_*.json\"\n",
    "    matching_files = list(checkpoint_dir.glob(pattern))\n",
    "    \n",
    "    if not matching_files:\n",
    "        print(f\"No checkpoints found for PDF: {pdf_name} (sector: {sector})\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âš ï¸  WARNING: About to delete {len(matching_files)} checkpoint(s) for:\")\n",
    "    print(f\"   PDF: {pdf_name}\")\n",
    "    print(f\"   Sector: {sector}\")\n",
    "    \n",
    "    for cp in matching_files:\n",
    "        cp.unlink()\n",
    "        print(f\"   Deleted: {cp.name}\")\n",
    "    \n",
    "    print(f\"\\nâœ“ Cleared all checkpoints for {pdf_name}\")\n",
    "\n",
    "\n",
    "# Display configuration\n",
    "provider_lower = PROVIDER.lower().strip()\n",
    "if provider_lower == \"ollama\":\n",
    "    model_name = OLLAMA_CONFIG[\"model\"]\n",
    "elif provider_lower == \"groq\":\n",
    "    model_name = GROQ_CONFIG[\"model\"]\n",
    "elif provider_lower == \"anthropic\":\n",
    "    model_name = ANTHROPIC_CONFIG[\"model\"]\n",
    "elif provider_lower == \"openai\":\n",
    "    model_name = OPENAI_CONFIG[\"model\"]\n",
    "else:\n",
    "    model_name = f\"unknown (PROVIDER={PROVIDER})\"\n",
    "print(f\"âœ“ LLM factory function defined\")\n",
    "print(f\"âœ“ Checkpoint system initialized\")\n",
    "print(f\"âœ“ Ready to use {PROVIDER.upper()} provider with model: {model_name}\")\n",
    "print(f\"\\nğŸ“‹ Checkpoint Features:\")\n",
    "print(f\"  â€¢ Timestamped auto-save (preserves version history)\")\n",
    "print(f\"  â€¢ Auto-loads latest checkpoint\")\n",
    "print(f\"  â€¢ Per-agent control (USE_CHECKPOINT_AGENT1/2/3)\")\n",
    "print(f\"  â€¢ Supports 17 agents: agent1, agent2, agent3_1..agent3_11, agent4_1..agent4_3, agent5\")\n",
    "print(f\"  â€¢ PDF-specific checkpoints (unique per document)\")\n",
    "print(f\"  â€¢ New PDF detection (automatic full pipeline trigger)\")\n",
    "print(f\"  â€¢ cleanup_old_checkpoints() utility\")\n",
    "\n",
    "if PROVIDER == \"ollama\" and \"keep_alive\" in OLLAMA_CONFIG:\n",
    "    print(f\"\\nâœ“ Model will stay loaded in memory for: {OLLAMA_CONFIG['keep_alive']}\")\n",
    "\n",
    "# Show status for current PDF\n",
    "show_current_pdf_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ—‚ï¸ Checkpoint Management Utilities\n",
    "\n",
    "Use these cells to manage your checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR ALL CHECKPOINTS\n",
    "# Uncomment and run to delete ALL checkpoints (fresh start)\n",
    "\n",
    "# import shutil\n",
    "# checkpoint_dir = Path(CHECKPOINT_DIR)\n",
    "# if checkpoint_dir.exists():\n",
    "#     shutil.rmtree(checkpoint_dir)\n",
    "#     checkpoint_dir.mkdir()\n",
    "#     print(\"âœ“ All checkpoints cleared!\")\n",
    "# else:\n",
    "#     print(\"No checkpoints directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAR SPECIFIC CHECKPOINT\n",
    "# Uncomment and run to delete a specific checkpoint\n",
    "\n",
    "# import os\n",
    "# checkpoint_to_delete = \"agent1\"  # or \"agent2\", \"agent3\"\n",
    "# checkpoint_path = get_checkpoint_path(checkpoint_to_delete, PDF_PATH, SECTOR)\n",
    "# if checkpoint_path.exists():\n",
    "#     os.remove(checkpoint_path)\n",
    "#     print(f\"âœ“ Deleted checkpoint: {checkpoint_path.name}\")\n",
    "# else:\n",
    "#     print(f\"Checkpoint not found: {checkpoint_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoints found.\n"
     ]
    }
   ],
   "source": [
    "# LIST ALL CHECKPOINTS\n",
    "# Run this cell to see all saved checkpoints\n",
    "\n",
    "list_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Cleanup utility ready. Uncomment the lines above to clean old checkpoints.\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP OLD CHECKPOINTS\n",
    "# Run this cell to keep only recent checkpoints and delete older ones\n",
    "\n",
    "# Keep only the 3 most recent checkpoints for each agent\n",
    "# Uncomment the line below to run cleanup:\n",
    "# cleanup_old_checkpoints(\"all\", keep_latest=3)\n",
    "\n",
    "# Or clean specific agent:\n",
    "# cleanup_old_checkpoints(\"agent1\", keep_latest=5)\n",
    "\n",
    "print(\"ğŸ’¡ Cleanup utility ready. Uncomment the lines above to clean old checkpoints.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AGENT 1: Document Extraction Agent\n",
    "\n",
    "**Purpose**: Extract substantive content relevant for business opportunity identification\n",
    "\n",
    "**What it does**:\n",
    "- Loads the PDF document using PyMuPDF (faster and more accurate than PyPDF)\n",
    "- Identifies and extracts key information relevant for business opportunity analysis\n",
    "- Eliminates noise (disclaimers, formatting artifacts, irrelevant data)\n",
    "- Returns structured, actionable insights\n",
    "- **Automatically handles large documents** with intelligent chunking\n",
    "\n",
    "**PDF Extraction**: Uses **PyMuPDFLoader** for superior text extraction quality and performance\n",
    "\n",
    "**Focus Areas**:\n",
    "- Market gaps and customer pain points\n",
    "- Emerging trends and opportunities\n",
    "- Critical metrics and performance indicators\n",
    "- Strategic insights for business evaluation\n",
    "\n",
    "**Large Document Handling** (Provider-Agnostic):\n",
    "\n",
    "The system automatically adapts to different provider token limits:\n",
    "\n",
    "| Provider | Context Window | Handling Strategy |\n",
    "|----------|----------------|-------------------|\n",
    "| **Groq** | ~8K tokens safe | Auto-chunks large PDFs into ~8K token pieces |\n",
    "| **Ollama** | ~8K tokens safe | Auto-chunks large PDFs into ~8K token pieces |\n",
    "| **Anthropic** | ~150K tokens | Processes most PDFs in single request |\n",
    "| **OpenAI** | ~100K tokens | Processes most PDFs in single request |\n",
    "\n",
    "**Chunking Strategy** (when needed):\n",
    "1. **Detection**: Automatically detects if PDF exceeds provider's token limit\n",
    "2. **Smart Splitting**: Splits on paragraph boundaries for context preservation\n",
    "3. **Parallel Processing**: Processes each chunk with same extraction prompt\n",
    "4. **Synthesis**: Combines chunk results into coherent analysis, removing duplicates\n",
    "\n",
    "**Recommendation for Large PDFs** (70+ pages):\n",
    "- **Development/Testing**: Use Groq with auto-chunking (free, fast, automatic)\n",
    "- **Production**: Switch to Anthropic or OpenAI for single-pass processing (better quality, no chunking needed)\n",
    "\n",
    "**Example - Switching Provider for Large PDF**:\n",
    "```python\n",
    "# In configuration cell (Cell 5), simply change:\n",
    "PROVIDER = \"anthropic\"  # or \"openai\"\n",
    "\n",
    "# System automatically:\n",
    "# - Uses larger context window (150K tokens for Anthropic)\n",
    "# - Processes 70-page PDF in single request\n",
    "# - No chunking needed, better coherence\n",
    "```\n",
    "\n",
    "**Temperature**: 0.3 (low - for focused, consistent extraction)\n",
    "**Provider**: Works with any configured LLM provider (auto-adapts to limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Extraction Agent prompts loaded\n"
     ]
    }
   ],
   "source": [
    "# AGENT 1: PROMPTS\n",
    "\n",
    "EXTRACTION_SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized agent focused on extracting substantive content from documents.\n",
    "\n",
    "Your task is to isolate ONLY the content relevant for identifying and evaluating potential \n",
    "business opportunities across critical dimensions.\n",
    "\n",
    "SUBSTANTIVE CONTENT TO EXTRACT (focus on business opportunity analysis):\n",
    "- Market gaps, unmet needs, or customer pain points\n",
    "- Emerging trends, technological shifts, or regulatory changes\n",
    "- Competitive landscape insights and market positioning opportunities\n",
    "- Revenue models, pricing strategies, or monetization approaches\n",
    "- Customer segments, target audiences, and demand indicators\n",
    "- Operational capabilities, resources, or infrastructure mentioned\n",
    "- Strategic partnerships, alliances, or collaboration opportunities\n",
    "- Financial performance indicators relevant to market viability\n",
    "- Risk factors that could impact business feasibility\n",
    "- Innovation opportunities or areas for differentiation\n",
    "- Growth projections, market size estimates, or scalability indicators\n",
    "\n",
    "NOISE TO ELIMINATE:\n",
    "- Standard disclaimers, legal boilerplate, and compliance statements\n",
    "- Formatting artifacts, page numbers, headers, and footers\n",
    "- Redundant executive summaries or table of contents\n",
    "- Generic background information without actionable insights\n",
    "- Administrative details irrelevant to business opportunity assessment\n",
    "- Historical data without forward-looking implications\n",
    "- Routine operational updates that don't reveal opportunities\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return the substantive content organized by relevance to business opportunity identification.\n",
    "Use clear sections with concise bullet points. Prioritize actionable insights over descriptive information.\n",
    "\n",
    "Structure your output as:\n",
    "\n",
    "**KEY MARKET INSIGHTS:**\n",
    "- Insight 1\n",
    "- Insight 2\n",
    "\n",
    "**CRITICAL METRICS:**\n",
    "- Metric 1: Value\n",
    "- Metric 2: Value\n",
    "\n",
    "**IDENTIFIED OPPORTUNITIES:**\n",
    "- Opportunity 1\n",
    "- Opportunity 2\n",
    "\n",
    "**MARKET CHALLENGES:**\n",
    "- Challenge 1\n",
    "- Challenge 2\n",
    "\n",
    "**STRATEGIC SUMMARY:**\n",
    "[2-3 sentences summarizing the most important findings for business opportunity evaluation]\n",
    "\"\"\"\n",
    "\n",
    "EXTRACTION_USER_PROMPT = \"\"\"\n",
    "Analyze the following document from the {sector} sector.\n",
    "\n",
    "CONTEXT: This analysis will feed into a subsequent evaluation for business idea generation.\n",
    "Extract ONLY information that would be valuable for assessing viability, market potential, \n",
    "competitive advantage, and strategic positioning of potential business ideas.\n",
    "\n",
    "DOCUMENT:\n",
    "---\n",
    "{document_content}\n",
    "---\n",
    "\n",
    "Extract the substantive content following the specified format, eliminating all noise and \n",
    "irrelevant information.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ“ Extraction Agent prompts loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent 1 functions defined\n"
     ]
    }
   ],
   "source": [
    "# AGENT 1: IMPLEMENTATION\n",
    "\n",
    "def estimate_tokens(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Estimate token count for text (rough approximation: 1 token â‰ˆ 4 characters).\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to estimate\n",
    "        \n",
    "    Returns:\n",
    "        int: Estimated token count\n",
    "    \"\"\"\n",
    "    return len(text) // 4\n",
    "\n",
    "\n",
    "def get_max_tokens_for_provider() -> int:\n",
    "    \"\"\"\n",
    "    Get maximum safe input tokens for current provider.\n",
    "    Leaves room for system prompt and response.\n",
    "    \n",
    "    Returns:\n",
    "        int: Maximum safe tokens for document content\n",
    "    \"\"\"\n",
    "    if PROVIDER == \"groq\":\n",
    "        # Groq llama-3.3-70b has 12K TPM limit, use conservative limit\n",
    "        return 8000  # Leave room for prompts and response\n",
    "    elif PROVIDER == \"anthropic\":\n",
    "        # Claude has 200K context window\n",
    "        return 150000\n",
    "    elif PROVIDER == \"openai\":\n",
    "        # GPT-4o has 128K context\n",
    "        return 100000\n",
    "    elif PROVIDER == \"ollama\":\n",
    "        # Varies by model, use conservative default\n",
    "        return 8000\n",
    "    else:\n",
    "        return 8000\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_tokens: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into chunks that fit within token limit.\n",
    "    Tries to split on paragraph boundaries for better context.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to chunk\n",
    "        max_tokens (int): Maximum tokens per chunk\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: List of text chunks\n",
    "    \"\"\"\n",
    "    # Convert tokens to approximate characters\n",
    "    max_chars = max_tokens * 4\n",
    "    \n",
    "    # If text fits, return as single chunk\n",
    "    if len(text) <= max_chars:\n",
    "        return [text]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    # Split on double newlines (paragraph boundaries)\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        # If adding this paragraph would exceed limit\n",
    "        if len(current_chunk) + len(para) + 2 > max_chars:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk)\n",
    "                current_chunk = para\n",
    "            else:\n",
    "                # Single paragraph is too large, split it\n",
    "                for i in range(0, len(para), max_chars):\n",
    "                    chunks.append(para[i:i + max_chars])\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                current_chunk += \"\\n\\n\" + para\n",
    "            else:\n",
    "                current_chunk = para\n",
    "    \n",
    "    # Add remaining chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "\n",
    "def load_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Load PDF and return text content using PyMuPDF for better extraction quality.\n",
    "    \n",
    "    PyMuPDFLoader advantages:\n",
    "    - Faster extraction than PyPDF\n",
    "    - Better handling of complex layouts\n",
    "    - More accurate text extraction\n",
    "    - Preserves formatting better\n",
    "    \n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        str: Extracted text content from PDF\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“„ Loading PDF using PyMuPDF: {pdf_path}\")\n",
    "    loader = PyMuPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    content = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    num_chars = len(content)\n",
    "    num_pages = len(documents)\n",
    "    estimated_tokens = estimate_tokens(content)\n",
    "    \n",
    "    print(f\"âœ“ Loaded {num_chars:,} characters from {num_pages} page(s)\")\n",
    "    print(f\"âœ“ Estimated tokens: {estimated_tokens:,}\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "\n",
    "def extract_key_info(document_content: str, sector: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract substantive information from document content using AI.\n",
    "    Focuses on business opportunity identification, eliminating noise.\n",
    "    Automatically handles large documents with chunking.\n",
    "    \n",
    "    Args:\n",
    "        document_content (str): Raw document text\n",
    "        sector (str): Business sector for context\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Extracted information and metadata\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 1: Extracting substantive content using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Create LLM using factory function\n",
    "        llm = create_llm(temperature=0.3)  # Low temperature for focused extraction\n",
    "        \n",
    "        # Check if document needs chunking\n",
    "        estimated_tokens = estimate_tokens(document_content)\n",
    "        max_tokens = get_max_tokens_for_provider()\n",
    "        \n",
    "        print(f\"ğŸ“Š Document size: ~{estimated_tokens:,} tokens\")\n",
    "        print(f\"ğŸ“Š Provider limit: ~{max_tokens:,} tokens\")\n",
    "        \n",
    "        if estimated_tokens > max_tokens:\n",
    "            print(f\"âš ï¸  Document exceeds token limit - using chunking strategy\")\n",
    "            print(f\"   Splitting into chunks of ~{max_tokens:,} tokens each...\")\n",
    "            \n",
    "            # Split document into chunks\n",
    "            chunks = chunk_text(document_content, max_tokens)\n",
    "            print(f\"âœ“ Split into {len(chunks)} chunk(s)\")\n",
    "            \n",
    "            # Process each chunk\n",
    "            chunk_results = []\n",
    "            for i, chunk in enumerate(chunks, 1):\n",
    "                print(f\"\\nğŸ”„ Processing chunk {i}/{len(chunks)}...\")\n",
    "                \n",
    "                # Create prompt for this chunk\n",
    "                chunk_prompt = ChatPromptTemplate.from_messages([\n",
    "                    (\"system\", EXTRACTION_SYSTEM_PROMPT),\n",
    "                    (\"user\", EXTRACTION_USER_PROMPT)\n",
    "                ])\n",
    "                \n",
    "                messages = chunk_prompt.format_messages(\n",
    "                    sector=sector,\n",
    "                    document_content=chunk\n",
    "                )\n",
    "                \n",
    "                response = llm.invoke(messages)\n",
    "                chunk_results.append(response.content)\n",
    "                print(f\"âœ“ Chunk {i}/{len(chunks)} processed\")\n",
    "            \n",
    "            # Combine chunk results\n",
    "            print(f\"\\nğŸ”„ Combining {len(chunk_results)} chunk results...\")\n",
    "            \n",
    "            # Create a synthesis prompt to combine chunks\n",
    "            synthesis_prompt = f\"\"\"You are synthesizing multiple extractions from different parts of a document.\n",
    "\n",
    "Below are {len(chunk_results)} separate extractions from different sections of a {sector} sector document.\n",
    "Your task is to combine them into a single, coherent analysis without redundancy.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Merge similar insights from different chunks\n",
    "2. Remove duplicate information\n",
    "3. Organize by the standard output format (Key Market Insights, Critical Metrics, etc.)\n",
    "4. Preserve all unique data points and metrics\n",
    "5. Maintain the most important information from each chunk\n",
    "\n",
    "CHUNK EXTRACTIONS:\n",
    "---\n",
    "\"\"\" + \"\\n\\n---\\n\\n\".join([f\"CHUNK {i+1}:\\n{result}\" for i, result in enumerate(chunk_results)]) + \"\"\"\n",
    "---\n",
    "\n",
    "Synthesize these into a single, well-organized extraction following the standard output format.\"\"\"\n",
    "            \n",
    "            synthesis_messages = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", \"You are a business analyst synthesizing document extractions.\"),\n",
    "                (\"user\", synthesis_prompt)\n",
    "            ]).format_messages()\n",
    "            \n",
    "            synthesis_response = llm.invoke(synthesis_messages)\n",
    "            result = synthesis_response.content\n",
    "            \n",
    "            print(\"âœ“ Synthesis complete\")\n",
    "        else:\n",
    "            print(\"âœ“ Document fits within token limit - processing in single request\")\n",
    "            \n",
    "            # Create prompt\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", EXTRACTION_SYSTEM_PROMPT),\n",
    "                (\"user\", EXTRACTION_USER_PROMPT)\n",
    "            ])\n",
    "            \n",
    "            # Get response\n",
    "            messages = prompt.format_messages(\n",
    "                sector=sector,\n",
    "                document_content=document_content\n",
    "            )\n",
    "            \n",
    "            response = llm.invoke(messages)\n",
    "            result = response.content\n",
    "        \n",
    "        print(\"âœ“ Extraction complete\")\n",
    "        \n",
    "        extraction_result = {\n",
    "            \"raw_output\": result,\n",
    "            \"sector\": sector,\n",
    "            \"chunked\": estimated_tokens > max_tokens,\n",
    "            \"num_chunks\": len(chunks) if estimated_tokens > max_tokens else 1\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\"agent1\", extraction_result)\n",
    "        \n",
    "        return extraction_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error during extraction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ Agent 1 functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, running Agent 1...\n",
      "ğŸ“„ Loading PDF using PyMuPDF: data/EITUM_MDS-study_long (3).pdf\n",
      "âœ“ Loaded 167,286 characters from 70 page(s)\n",
      "âœ“ Estimated tokens: 41,821\n",
      "\n",
      "ğŸ¤– Agent 1: Extracting substantive content using ANTHROPIC...\n",
      "ğŸ“Š Document size: ~41,821 tokens\n",
      "ğŸ“Š Provider limit: ~150,000 tokens\n",
      "âœ“ Document fits within token limit - processing in single request\n",
      "âœ“ Extraction complete\n",
      "ğŸ’¾ Checkpoint saved: agent1_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-45-24.json\n",
      "\n",
      "================================================================================\n",
      "AGENT 1 OUTPUT:\n",
      "================================================================================\n",
      "**KEY MARKET INSIGHTS:**\n",
      "- Data is a key strategic asset for the European Strategy for Sustainable and Smart Mobility, enabling priorities like improving road safety, promoting alternative mobility modes, and boosting advanced mobility services.\n",
      "- Mobility data spaces can facilitate greater availability and accessibility to data, as well as promote trusted environments for secure data sharing.\n",
      "- Mobility data spaces have the potential to enable new public and commercial business models and services by unlocking access to existing data while respecting usage control and privacy for data owners.\n",
      "\n",
      "**CRITICAL METRICS:**\n",
      "- Over 80% of the European population have access to mobile internet, with data consumption forecast to triple by 2028.\n",
      "- Less than 1% of freight transport operations within the EU are completely paperless.\n",
      "\n",
      "**IDENTIFIED OPPORTUNITIES:**\n",
      "- Mobility data spaces can accelerate multimodal integration projects and MaaS platforms by encouraging the sharing of more and better data.\n",
      "- Data spaces can facilitate the monetization of data, adding validity to the business models of new mobility services.\n",
      "- Mobility data spaces can transform the rail sector towards a more digitalized and interoperable European railway system.\n",
      "- Data spaces can provide the mechanisms and framework for a more controllable and traceable data-driven service ecosystem, helping the private sector meet complex data-related regulations.\n",
      "\n",
      "**MARKET CHALLENGES:**\n",
      "- Fragmentation of mobility data and lack of interoperability between heterogeneous systems.\n",
      "- Resistance from organizations to share proprietary data and incorporate data sharing into internal data management.\n",
      "- Ambiguity in calculating the value of data and defining sustainable business models for data spaces.\n",
      "- Varying levels of maturity in implementing regulations like the ITS Directive across Member States.\n",
      "\n",
      "**STRATEGIC SUMMARY:**\n",
      "Mobility data spaces have significant potential to positively disrupt the mobility sector towards more efficient, sustainable, and safe transport systems in Europe. However, realizing this potential will require overcoming commercial challenges, aligning regulation implementation across Member States, and incentivizing public-private investment to accelerate the development and adoption of mobility data spaces.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENT 1 (with checkpoint support)\n",
    "\n",
    "# Try to load from checkpoint first\n",
    "extraction_result = load_checkpoint(\"agent1\")\n",
    "\n",
    "if extraction_result is None:\n",
    "    # No checkpoint found, run Agent 1\n",
    "    print(\"No checkpoint found, running Agent 1...\")\n",
    "    \n",
    "    # Load PDF\n",
    "    document_text = load_pdf(PDF_PATH)\n",
    "    \n",
    "    # Extract information\n",
    "    extraction_result = extract_key_info(document_text, SECTOR)\n",
    "else:\n",
    "    print(\"âœ“ Using cached extraction result\")\n",
    "\n",
    "# Display results\n",
    "if extraction_result:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AGENT 1 OUTPUT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(extraction_result[\"raw_output\"])\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\nâŒ Agent 1 failed to produce results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AGENT 2: Business Idea Generation Agent\n",
    "\n",
    "**Purpose**: Generate innovative, viable business ideas based on extracted market intelligence\n",
    "\n",
    "**What it does**:\n",
    "- Takes substantive content from Agent 1\n",
    "- Identifies concrete business opportunities addressing market gaps\n",
    "- Creates detailed, actionable business concepts\n",
    "- Ensures ideas are grounded in market data and trends\n",
    "\n",
    "**Focus Areas**:\n",
    "- Market gaps and unmet customer needs\n",
    "- Scalable business models\n",
    "- Revenue generation strategies\n",
    "- Competitive differentiation\n",
    "- Implementation feasibility\n",
    "\n",
    "**Output Components** (for each idea):\n",
    "1. Business Concept - Core value proposition and target segment\n",
    "2. Market Opportunity - Gap/need, market size, growth drivers\n",
    "3. Solution Approach - Offering, features, technology, differentiation\n",
    "4. Revenue Model - Monetization, pricing, revenue streams\n",
    "5. Competitive Advantage - Unique position, barriers, sustainability\n",
    "6. Implementation Path - Resources, success factors, challenges\n",
    "7. Growth Potential - Scalability, expansion, vision\n",
    "\n",
    "**Temperature**: 0.8 (high - for creative idea generation)\n",
    "**Provider**: Works with any configured LLM provider (Ollama/Groq/Anthropic/OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Idea Generation Agent prompts loaded\n"
     ]
    }
   ],
   "source": [
    "# AGENT 2: PROMPTS\n",
    "\n",
    "IDEA_GENERATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized business strategist focused on generating innovative, viable business ideas.\n",
    "\n",
    "Your task is to analyze market intelligence and create concrete business opportunities that address \n",
    "identified gaps, leverage emerging trends, and have realistic paths to implementation.\n",
    "\n",
    "CORE PRINCIPLES:\n",
    "- Ground ideas in real market data and identified opportunities\n",
    "- Focus on scalability and sustainable competitive advantage\n",
    "- Ensure technical and operational feasibility\n",
    "- Address genuine customer pain points\n",
    "- Propose clear revenue models\n",
    "BUSINESS IDEA COMPONENTS (include all for each idea):\n",
    "\n",
    "1. **Business Concept**\n",
    "\n",
    "   - Clear, concise description (2-3 sentences)\n",
    "   - Core value proposition\n",
    "   - Target customer segment\n",
    "\n",
    "2. **Market Opportunity**\n",
    "   - Specific gap or need being addressed\n",
    "   - Market size and growth potential\n",
    "   - Supporting data from market intelligence\n",
    "\n",
    "3. **Solution Approach**\n",
    "   - Key features or service offerings\n",
    "   - Technology or methodology employed\n",
    "   - Differentiation from existing solutions\n",
    "\n",
    "4. **Revenue Model**\n",
    "   - Primary monetization strategy\n",
    "   - Pricing approach\n",
    "   - Revenue potential indicators\n",
    "\n",
    "5. **Competitive Advantage**\n",
    "   - Unique positioning\n",
    "   - Barriers to entry for competitors\n",
    "   - Sustainable differentiation factors\n",
    "\n",
    "6. **Implementation Path**\n",
    "   - Key resources required (technology, partnerships, expertise)\n",
    "   - Critical success factors\n",
    "   - Potential challenges and mitigation strategies\n",
    "\n",
    "7. **Growth Potential**\n",
    "   - Scalability factors\n",
    "   - Expansion opportunities\n",
    "   - Long-term vision\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "For each business idea, use this exact structure (replace content in square brackets):\n",
    "\n",
    "---\n",
    "### BUSINESS IDEA #[NUMBER]: [Short Descriptive Title]\n",
    "\n",
    "**Business Concept:**\n",
    "[2-3 sentence description]\n",
    "\n",
    "**Market Opportunity:**\n",
    "- Gap/Need: [specific problem being solved]\n",
    "- Market Size: [addressable market with data]\n",
    "- Growth Drivers: [factors supporting opportunity]\n",
    "\n",
    "**Solution Approach:**\n",
    "- Core Offering: [what the business provides]\n",
    "- Key Features: [main capabilities or services]\n",
    "- Technology/Methodology: [approach to delivery]\n",
    "- Differentiation: [what makes it unique]\n",
    "\n",
    "**Revenue Model:**\n",
    "- Monetization: [how money is made]\n",
    "- Pricing Strategy: [pricing approach]\n",
    "- Revenue Streams: [multiple income sources if applicable]\n",
    "\n",
    "**Competitive Advantage:**\n",
    "- Unique Position: [strategic positioning]\n",
    "- Barriers to Entry: [what protects the business]\n",
    "- Sustainability: [long-term defensibility]\n",
    "\n",
    "**Implementation Path:**\n",
    "- Required Resources: [key assets, technology, partnerships]\n",
    "- Success Factors: [critical elements for success]\n",
    "- Key Challenges: [main obstacles and solutions]\n",
    "\n",
    "**Growth Potential:**\n",
    "- Scalability: [how it can grow]\n",
    "- Expansion Options: [future opportunities]\n",
    "- Vision: [long-term potential]\n",
    "\n",
    "---\n",
    "\n",
    "QUALITY CRITERIA:\n",
    "- Ideas must be specific, not generic concepts\n",
    "- Each idea should be distinctly different from others\n",
    "- Ground all claims in the provided market intelligence\n",
    "- Ensure ideas are actionable, not purely theoretical\n",
    "- Balance innovation with feasibility\n",
    "\"\"\"\n",
    "\n",
    "IDEA_GENERATION_USER_PROMPT = \"\"\"\n",
    "Based on the market intelligence extracted from the {sector} sector, generate {num_ideas} distinct, \n",
    "viable business ideas.\n",
    "\n",
    "CONTEXT: \n",
    "These ideas will be rigorously evaluated on scalability, feasibility, market size, innovation, \n",
    "and risk. Focus on opportunities with strong potential across multiple dimensions.\n",
    "\n",
    "MARKET INTELLIGENCE:\n",
    "---\n",
    "{extracted_info}\n",
    "---\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Each idea must address a specific opportunity or gap identified in the market intelligence\n",
    "2. Ideas should be complementary but distinct (different approaches, markets, or solutions)\n",
    "3. Include all required components in the specified output format\n",
    "4. Use concrete data and metrics from the market intelligence to support each idea\n",
    "5. Ensure ideas are actionable with clear implementation paths\n",
    "\n",
    "Generate {num_ideas} business ideas following the exact output format specified in your system prompt.\n",
    "Number them as BUSINESS IDEA #1, BUSINESS IDEA #2, BUSINESS IDEA #3, etc.\n",
    "\"\"\"\n",
    "\n",
    "print(\"âœ“ Idea Generation Agent prompts loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent 2 functions defined\n"
     ]
    }
   ],
   "source": [
    "# AGENT 2: IMPLEMENTATION\n",
    "\n",
    "def generate_ideas(extraction_output: str, sector: str, num_ideas: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Generate business ideas based on extracted market intelligence.\n",
    "    \n",
    "    Args:\n",
    "        extraction_output (str): Substantive content from Agent 1\n",
    "        sector (str): Business sector for context\n",
    "        num_ideas (int): Number of ideas to generate (default: 3)\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Generated business ideas and metadata\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 2: Generating {num_ideas} business ideas using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Create LLM using factory function\n",
    "        llm = create_llm(temperature=0.8)  # Higher temperature for creativity\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", IDEA_GENERATION_SYSTEM_PROMPT),\n",
    "            (\"user\", IDEA_GENERATION_USER_PROMPT)\n",
    "        ])\n",
    "        \n",
    "        # Get response\n",
    "        messages = prompt.format_messages(\n",
    "            sector=sector,\n",
    "            num_ideas=num_ideas,\n",
    "            extracted_info=extraction_output\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        result = response.content\n",
    "        \n",
    "        print(\"âœ“ Idea generation complete\")\n",
    "        \n",
    "        ideas_result = {\n",
    "            \"raw_output\": result,\n",
    "            \"sector\": sector\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint automatically\n",
    "        save_checkpoint(\"agent2\", ideas_result)\n",
    "        \n",
    "        return ideas_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error during idea generation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ“ Agent 2 functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No checkpoint found, running Agent 2...\n",
      "\n",
      "ğŸ¤– Agent 2: Generating 3 business ideas using ANTHROPIC...\n",
      "âœ“ Idea generation complete\n",
      "ğŸ’¾ Checkpoint saved: agent2_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-51-04.json\n",
      "\n",
      "================================================================================\n",
      "AGENT 2 OUTPUT:\n",
      "================================================================================\n",
      "Understood. Here are 3 distinct, viable business ideas based on the provided market intelligence:\n",
      "\n",
      "---\n",
      "### BUSINESS IDEA #1: Mobility Data Marketplace\n",
      "\n",
      "**Business Concept:**\n",
      "A secure, trusted platform that enables the seamless exchange of mobility data between public and private sector stakeholders, unlocking new revenue streams and accelerating the development of innovative mobility services.\n",
      "\n",
      "**Market Opportunity:**\n",
      "- Gap/Need: Fragmentation of mobility data and lack of interoperability between systems, hindering the development of integrated mobility solutions.\n",
      "- Market Size: Over 80% of the European population have access to mobile internet, with data consumption forecast to triple by 2028. Less than 1% of freight transport operations within the EU are completely paperless.\n",
      "- Growth Drivers: Increasing demand for data-driven mobility services and the European Strategy for Sustainable and Smart Mobility's focus on improving data availability and accessibility.\n",
      "\n",
      "**Solution Approach:**\n",
      "- Core Offering: A secure, cloud-based marketplace platform that facilitates the trading of mobility data between data owners and consumers.\n",
      "- Key Features: Standardized data formats, trusted data access controls, revenue sharing mechanisms, and advanced analytics tools.\n",
      "- Technology/Methodology: Blockchain-based data exchange, AI-powered data valuation, and cloud-native architecture.\n",
      "- Differentiation: Comprehensive data management framework, transparent governance, and neutral, trusted intermediary role.\n",
      "\n",
      "**Revenue Model:**\n",
      "- Monetization: Commission-based revenue sharing on data transactions, subscription fees for advanced analytics, and value-added services.\n",
      "- Pricing Strategy: Dynamic, market-driven pricing based on data type, volume, and demand.\n",
      "- Revenue Streams: Data trading commissions, subscription fees, and revenue-sharing from complementary services.\n",
      "\n",
      "**Competitive Advantage:**\n",
      "- Unique Position: Neutral, trusted platform that brings together diverse mobility data stakeholders.\n",
      "- Barriers to Entry: Extensive data governance expertise, established industry partnerships, and regulatory compliance.\n",
      "- Sustainability: Network effects, data monetization expertise, and ongoing investment in platform capabilities.\n",
      "\n",
      "**Implementation Path:**\n",
      "- Required Resources: Data integration expertise, cloud infrastructure, blockchain technology, and extensive industry partnerships.\n",
      "- Success Factors: Widespread adoption by data owners and consumers, seamless data onboarding and exchange, and robust data governance frameworks.\n",
      "- Key Challenges: Overcoming data sharing resistance, aligning with varying data regulations across Member States, and securing initial critical mass of participants.\n",
      "\n",
      "**Growth Potential:**\n",
      "- Scalability: Ability to onboard new data sources and expand into adjacent mobility verticals.\n",
      "- Expansion Options: Offering value-added services like predictive analytics, AI-powered insights, and customized data products.\n",
      "- Vision: Become the de facto data exchange platform for the European mobility ecosystem, enabling new data-driven business models and services.\n",
      "\n",
      "---\n",
      "### BUSINESS IDEA #2: Mobility Data-as-a-Service (MDaaS) Platform\n",
      "\n",
      "**Business Concept:**\n",
      "A comprehensive, cloud-based platform that provides secure, on-demand access to curated mobility data sets and advanced analytics, empowering public and private sector organizations to develop innovative mobility solutions.\n",
      "\n",
      "**Market Opportunity:**\n",
      "- Gap/Need: Fragmentation of mobility data and lack of interoperability between heterogeneous systems, hindering the development of integrated mobility solutions.\n",
      "- Market Size: Over 80% of the European population have access to mobile internet, with data consumption forecast to triple by 2028. Less than 1% of freight transport operations within the EU are completely paperless.\n",
      "- Growth Drivers: Increasing demand for data-driven mobility services and the European Strategy for Sustainable and Smart Mobility's focus on improving data availability and accessibility.\n",
      "\n",
      "**Solution Approach:**\n",
      "- Core Offering: A cloud-based platform that provides on-demand access to curated mobility data sets and advanced analytics tools.\n",
      "- Key Features: Data aggregation, normalization, and enrichment; secure data access controls; AI-powered analytics; and customizable data products.\n",
      "- Technology/Methodology: Cloud-native architecture, machine learning, and API-driven integration with data sources.\n",
      "- Differentiation: Comprehensive data management capabilities, industry-specific expertise, and flexible, scalable service model.\n",
      "\n",
      "**Revenue Model:**\n",
      "- Monetization: Subscription-based pricing for data access and analytics, revenue sharing on data-driven services, and custom data product development.\n",
      "- Pricing Strategy: Tiered pricing based on data volume, analytics complexity, and service level agreements.\n",
      "- Revenue Streams: Subscription fees, revenue sharing, and professional services.\n",
      "\n",
      "**Competitive Advantage:**\n",
      "- Unique Position: One-stop-shop for mobility data and analytics, catering to diverse public and private sector use cases.\n",
      "- Barriers to Entry: Extensive data integration and management expertise, advanced analytics capabilities, and established industry partnerships.\n",
      "- Sustainability: Continuous investment in data sources, analytics, and platform enhancements to maintain competitive edge.\n",
      "\n",
      "**Implementation Path:**\n",
      "- Required Resources: Data engineering and integration expertise, cloud infrastructure, advanced analytics capabilities, and industry partnerships.\n",
      "- Success Factors: Comprehensive data catalog, seamless user experience, and strong data governance framework.\n",
      "- Key Challenges: Onboarding diverse data sources, ensuring data quality and security, and aligning with evolving regulatory requirements.\n",
      "\n",
      "**Growth Potential:**\n",
      "- Scalability: Ability to expand data sources, analytics capabilities, and customer base across mobility verticals.\n",
      "- Expansion Options: Offering customized data products, consulting services, and API-driven integration with third-party applications.\n",
      "- Vision: Become the leading data-driven mobility platform, enabling a wide range of innovative mobility solutions and services.\n",
      "\n",
      "---\n",
      "### BUSINESS IDEA #3: Mobility Data Integration-as-a-Service (MDIaaS)\n",
      "\n",
      "**Business Concept:**\n",
      "A service-based solution that helps public and private sector organizations seamlessly integrate and leverage mobility data from disparate sources, accelerating the development of advanced mobility applications and services.\n",
      "\n",
      "**Market Opportunity:**\n",
      "- Gap/Need: Fragmentation of mobility data and lack of interoperability between heterogeneous systems, hindering the development of integrated mobility solutions.\n",
      "- Market Size: Over 80% of the European population have access to mobile internet, with data consumption forecast to triple by 2028. Less than 1% of freight transport operations within the EU are completely paperless.\n",
      "- Growth Drivers: Increasing demand for data-driven mobility services and the European Strategy for Sustainable and Smart Mobility's focus on improving data availability and accessibility.\n",
      "\n",
      "**Solution Approach:**\n",
      "- Core Offering: A managed service that provides end-to-end mobility data integration, normalization, and enrichment capabilities.\n",
      "- Key Features: Data source onboarding, API development, data transformation and harmonization, and data quality management.\n",
      "- Technology/Methodology: Cloud-based data integration platform, API management, and machine learning-powered data processing.\n",
      "- Differentiation: Comprehensive data integration expertise, industry-specific knowledge, and flexible, scalable service model.\n",
      "\n",
      "**Revenue Model:**\n",
      "- Monetization: Subscription-based pricing for data integration services, professional services for custom development, and revenue sharing on data-driven solutions.\n",
      "- Pricing Strategy: Tiered pricing based on data volume, integration complexity, and service level agreements.\n",
      "- Revenue Streams: Subscription fees, professional services, and revenue sharing.\n",
      "\n",
      "**Competitive Advantage:**\n",
      "- Unique Position: Dedicated focus on mobility data integration, offering a turnkey solution for organizations to leverage diverse data sources.\n",
      "- Barriers to Entry: Extensive data integration expertise, industry-specific knowledge, and established partnerships with mobility data providers.\n",
      "- Sustainability: Continuous investment in platform capabilities, data source expansion, and value-added services to maintain competitive edge.\n",
      "\n",
      "**Implementation Path:**\n",
      "- Required Resources: Data integration engineers, cloud infrastructure, API management capabilities, and industry partnerships.\n",
      "- Success Factors: Comprehensive data source connectivity, seamless data transformation and harmonization, and robust data quality management.\n",
      "- Key Challenges: Onboarding diverse data sources, ensuring data security and privacy, and aligning with evolving regulatory requirements.\n",
      "\n",
      "**Growth Potential:**\n",
      "- Scalability: Ability to expand data source coverage, service offerings, and customer base across mobility verticals.\n",
      "- Expansion Options: Offering value-added services like predictive analytics, data monetization, and custom application development.\n",
      "- Vision: Become the leading data integration partner for the European mobility ecosystem, enabling a wide range of innovative mobility solutions and services.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENT 2 (with checkpoint support)\n",
    "\n",
    "# Try to load from checkpoint first\n",
    "ideas_result = load_checkpoint(\"agent2\")\n",
    "\n",
    "if ideas_result is None:\n",
    "    # No checkpoint found, run Agent 2\n",
    "    print(\"No checkpoint found, running Agent 2...\")\n",
    "    \n",
    "    if extraction_result:\n",
    "        ideas_result = generate_ideas(\n",
    "            extraction_output=extraction_result[\"raw_output\"],\n",
    "            sector=SECTOR,\n",
    "            num_ideas=NUM_IDEAS\n",
    "        )\n",
    "    else:\n",
    "        print(\"âŒ Cannot run Agent 2: Agent 1 results not available\")\n",
    "        ideas_result = None\n",
    "else:\n",
    "    print(\"âœ“ Using cached idea generation result\")\n",
    "\n",
    "# Display results\n",
    "if ideas_result:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AGENT 2 OUTPUT:\")\n",
    "    print(\"=\"*80)\n",
    "    print(ideas_result[\"raw_output\"])\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\nâŒ Agent 2 failed to produce results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AGENT 3: Dimensional Evaluation Agents (3.1 - 3.11)\n",
    "\n",
    "**Purpose**: Rigorous evaluation of business ideas across 11 specialized dimensions\n",
    "\n",
    "**Architecture**:\n",
    "- 11 specialized sub-agents, each focused on one dimension\n",
    "- Each sub-agent produces a score (1-10) with detailed justification\n",
    "- Each sub-agent saves its own checkpoint (agent3_X where X is dimension number)\n",
    "- All sub-agents load from Agent 2 checkpoint\n",
    "\n",
    "**Evaluation Dimensions**:\n",
    "1. **Market Potential** - Market size, growth, and monetization capacity\n",
    "2. **Differentiated Approach and Positioning** - Clarity and uniqueness of positioning\n",
    "3. **Sustainable Competitive Advantage** - Long-term defensibility\n",
    "4. **Differentiating Element** - Single strongest feature or insight\n",
    "5. **Technical Feasibility** - Technical achievability with current technology\n",
    "6. **Affordable & Rapid Implementation** - Time and cost to MVP\n",
    "7. **AI Enablement for Core Value** - Meaningful AI enhancement\n",
    "8. **Barrier to Entry** - Difficulty for new entrants to compete\n",
    "9. **Scalable Technology & Operations** - Non-linear growth potential\n",
    "10. **Product-Focused Output** - Repeatable product vs service\n",
    "11. **Subscription-Based Platform Access** - Recurring revenue quality\n",
    "\n",
    "**Temperature**: 0.4 (medium-low - for consistent, balanced evaluation)\n",
    "**Provider**: Works with any configured LLM provider (Ollama/Groq/Anthropic/OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Defined 11 evaluation dimensions\n",
      "âœ“ Dimension evaluation prompts loaded\n"
     ]
    }
   ],
   "source": [
    "# AGENT 3: DIMENSION DEFINITIONS AND PROMPTS\n",
    "\n",
    "# Define all 11 dimensions with their evaluation criteria\n",
    "DIMENSIONS = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Market Potential\",\n",
    "        \"description\": \"Evaluates the size, growth, and monetization capacity of the target market\",\n",
    "        \"key_questions\": [\n",
    "            \"Is the Total Addressable Market (TAM) large and growing?\",\n",
    "            \"Is there a clear, reachable customer segment?\",\n",
    "            \"Are customers already spending money on similar solutions?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Demand strength, willingness to pay, market timing\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"Differentiated Approach and Positioning\",\n",
    "        \"description\": \"Assesses how clearly the business is positioned versus alternatives\",\n",
    "        \"key_questions\": [\n",
    "            \"Is the value proposition immediately understandable?\",\n",
    "            \"Does it target a niche others ignore or underserve?\",\n",
    "            \"Is the positioning defensible or just marketing language?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Clarity, focus, uniqueness of angle\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"Sustainable Competitive Advantage\",\n",
    "        \"description\": \"Measures long-term defensibility beyond initial traction\",\n",
    "        \"key_questions\": [\n",
    "            \"What prevents competitors from copying this?\",\n",
    "            \"Does advantage improve over time?\",\n",
    "            \"Is it structural (data, network effects, switching costs)?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Durability, compounding advantages\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"name\": \"Differentiating Element\",\n",
    "        \"description\": \"Evaluates the single strongest feature or insight that makes the product stand out\",\n",
    "        \"key_questions\": [\n",
    "            \"What is the 'one thing' users would miss most?\",\n",
    "            \"Is this differentiation real or cosmetic?\",\n",
    "            \"Does it directly solve a painful problem?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Clear 'why this wins' factor\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"name\": \"Technical Feasibility\",\n",
    "        \"description\": \"Assesses whether the solution is technically achievable with current technology\",\n",
    "        \"key_questions\": [\n",
    "            \"Can this be built with existing tools and skills?\",\n",
    "            \"Are there hard technical unknowns?\",\n",
    "            \"Is AI usage realistic or speculative?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Engineering realism, execution risk\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"name\": \"Affordable & Rapid Implementation\",\n",
    "        \"description\": \"Measures time and cost to reach a usable MVP\",\n",
    "        \"key_questions\": [\n",
    "            \"Can a working version be built quickly?\",\n",
    "            \"Is initial investment low relative to learning gained?\",\n",
    "            \"Can one small team execute it?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Capital efficiency, speed to market\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"name\": \"AI Enablement for Core Value\",\n",
    "        \"description\": \"Evaluates whether AI meaningfully enhances the core product\",\n",
    "        \"key_questions\": [\n",
    "            \"Does AI improve outcomes, scale, or cost structure?\",\n",
    "            \"Is AI central or replaceable?\",\n",
    "            \"Does performance improve with usage/data?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Real AI leverage, not superficial automation\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"name\": \"Barrier to Entry\",\n",
    "        \"description\": \"Assesses how difficult it is for new entrants to compete\",\n",
    "        \"key_questions\": [\n",
    "            \"Is there a learning curve, data moat, or regulatory barrier?\",\n",
    "            \"Does early entry create advantages?\",\n",
    "            \"Are integrations or workflows hard to replicate?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Friction for competitors, protection against fast followers\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 9,\n",
    "        \"name\": \"Scalable Technology & Operations\",\n",
    "        \"description\": \"Measures whether growth is non-linear (revenue grows faster than costs)\",\n",
    "        \"key_questions\": [\n",
    "            \"Can the system handle 10Ã— or 100Ã— users?\",\n",
    "            \"Does onboarding require human effort?\",\n",
    "            \"Are marginal costs close to zero?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Platform scalability, automation readiness\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 10,\n",
    "        \"name\": \"Product-Focused Output\",\n",
    "        \"description\": \"Evaluates whether the offering is a repeatable product rather than a service\",\n",
    "        \"key_questions\": [\n",
    "            \"Is value delivered through software output?\",\n",
    "            \"Is customization minimal?\",\n",
    "            \"Can customers self-serve?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Productization, repeatability, low dependency on people\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 11,\n",
    "        \"name\": \"Subscription-Based Platform Access\",\n",
    "        \"description\": \"Assesses recurring revenue quality and predictability\",\n",
    "        \"key_questions\": [\n",
    "            \"Is subscription the natural payment model?\",\n",
    "            \"Is there ongoing value justifying renewal?\",\n",
    "            \"Are switching costs increasing over time?\"\n",
    "        ],\n",
    "        \"looks_for\": \"Revenue stability, lifetime value, churn resistance\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generic system prompt template for dimensional evaluation\n",
    "DIMENSION_EVALUATION_SYSTEM_PROMPT = \"\"\"\n",
    "You are a specialized business evaluator focused on assessing business ideas on the dimension of: {dimension_name}.\n",
    "\n",
    "DIMENSION OVERVIEW:\n",
    "{dimension_description}\n",
    "\n",
    "KEY EVALUATION QUESTIONS:\n",
    "{key_questions}\n",
    "\n",
    "EVALUATION FOCUS:\n",
    "{looks_for}\n",
    "\n",
    "SCORING GUIDELINES (1-10 scale):\n",
    "- 9-10: Exceptional - Clear leader in this dimension, minimal concerns\n",
    "- 7-8: Strong - Solid fundamentals, manageable challenges\n",
    "- 5-6: Moderate - Viable but significant challenges exist\n",
    "- 3-4: Weak - Major concerns, questionable viability\n",
    "- 1-2: Poor - Not recommended, fundamental flaws\n",
    "\n",
    "YOUR TASK:\n",
    "Evaluate the business idea ONLY on this specific dimension. Provide:\n",
    "1. A score from 1-10\n",
    "2. A detailed justification (3-5 sentences) that:\n",
    "   - References specific elements from the business idea\n",
    "   - Addresses the key evaluation questions\n",
    "   - Explains the score with concrete evidence\n",
    "   - Identifies both strengths and weaknesses in this dimension\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "**Score:** X/10\n",
    "\n",
    "**Justification:**\n",
    "[Your detailed 3-5 sentence justification here, grounded in specific evidence from the business idea]\n",
    "\"\"\"\n",
    "\n",
    "DIMENSION_EVALUATION_USER_PROMPT = \"\"\"\n",
    "Evaluate the following business idea from the {sector} sector on the dimension of: {dimension_name}.\n",
    "\n",
    "MARKET CONTEXT:\n",
    "---\n",
    "{sector_context}\n",
    "---\n",
    "\n",
    "BUSINESS IDEA TO EVALUATE:\n",
    "---\n",
    "{business_idea}\n",
    "---\n",
    "\n",
    "Provide your evaluation following the output format specified in your system prompt.\n",
    "Focus ONLY on the {dimension_name} dimension.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"âœ“ Defined {len(DIMENSIONS)} evaluation dimensions\")\n",
    "print(\"âœ“ Dimension evaluation prompts loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent 3 dimensional evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# AGENT 3: IMPLEMENTATION FUNCTIONS\n",
    "\n",
    "def parse_ideas(ideas_output: str) -> List[str]:\n",
    "    \"\"\"Parse individual business ideas from Agent 2's output.\"\"\"\n",
    "    ideas = ideas_output.split(\"### BUSINESS IDEA #\")\n",
    "    parsed_ideas = []\n",
    "    for idea in ideas[1:]:\n",
    "        parsed_ideas.append(\"### BUSINESS IDEA #\" + idea)\n",
    "    return parsed_ideas\n",
    "\n",
    "\n",
    "def evaluate_dimension(dimension: Dict, business_idea: str, sector_context: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate a business idea on a specific dimension using AI.\n",
    "    \n",
    "    Args:\n",
    "        dimension: Dimension definition dict with name, description, etc.\n",
    "        business_idea: Business idea text from Agent 2\n",
    "        sector_context: Market context from Agent 1\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Evaluation result with score and justification\n",
    "    \"\"\"\n",
    "    dim_name = dimension[\"name\"]\n",
    "    print(f\"ğŸ¤– Agent 3.{dimension['id']}: Evaluating '{dim_name}' using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Create LLM using factory function\n",
    "        llm = create_llm(temperature=0.4)  # Medium-low temperature for consistent evaluation\n",
    "        \n",
    "        # Format key questions as numbered list\n",
    "        questions_formatted = \"\\n\".join([f\"{i+1}. {q}\" for i, q in enumerate(dimension[\"key_questions\"])])\n",
    "        \n",
    "        # Create prompt\n",
    "        system_prompt = DIMENSION_EVALUATION_SYSTEM_PROMPT.format(\n",
    "            dimension_name=dim_name,\n",
    "            dimension_description=dimension[\"description\"],\n",
    "            key_questions=questions_formatted,\n",
    "            looks_for=dimension[\"looks_for\"]\n",
    "        )\n",
    "        \n",
    "        user_prompt = DIMENSION_EVALUATION_USER_PROMPT.format(\n",
    "            sector=SECTOR,\n",
    "            dimension_name=dim_name,\n",
    "            sector_context=sector_context,\n",
    "            business_idea=business_idea\n",
    "        )\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", user_prompt)\n",
    "        ])\n",
    "        \n",
    "        # Get response\n",
    "        messages = prompt.format_messages()\n",
    "        response = llm.invoke(messages)\n",
    "        result = response.content\n",
    "        \n",
    "        # Parse score from output\n",
    "        score = None\n",
    "        try:\n",
    "            # Look for pattern like \"Score: 8/10\" or \"**Score:** 8/10\"\n",
    "            import re\n",
    "            score_match = re.search(r'\\*\\*Score:\\*\\*\\s*(\\d+(?:\\.\\d+)?)/10|\\bScore:\\s*(\\d+(?:\\.\\d+)?)/10', result)\n",
    "            if score_match:\n",
    "                score = float(score_match.group(1) or score_match.group(2))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f\"âœ“ Evaluation complete - Score: {score}/10\")\n",
    "        \n",
    "        evaluation_result = {\n",
    "            \"dimension_id\": dimension[\"id\"],\n",
    "            \"dimension_name\": dim_name,\n",
    "            \"score\": score,\n",
    "            \"raw_output\": result\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint for this dimension\n",
    "        checkpoint_name = f\"agent3_{dimension['id']}\"\n",
    "        save_checkpoint(checkpoint_name, evaluation_result)\n",
    "        \n",
    "        return evaluation_result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error during evaluation: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def evaluate_all_dimensions(business_idea: str, sector_context: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Evaluate business idea across all 11 dimensions.\n",
    "    \n",
    "    Args:\n",
    "        business_idea: Business idea text from Agent 2\n",
    "        sector_context: Market context from Agent 1\n",
    "        \n",
    "    Returns:\n",
    "        List of evaluation results for all dimensions\n",
    "    \"\"\"\n",
    "    evaluations = []\n",
    "    \n",
    "    for dimension in DIMENSIONS:\n",
    "        # Try to load from checkpoint first\n",
    "        checkpoint_name = f\"agent3_{dimension['id']}\"\n",
    "        cached_eval = load_checkpoint(checkpoint_name)\n",
    "        \n",
    "        if cached_eval is not None:\n",
    "            print(f\"âœ“ Using cached evaluation for '{dimension['name']}'\")\n",
    "            evaluations.append(cached_eval)\n",
    "        else:\n",
    "            # Run evaluation\n",
    "            evaluation = evaluate_dimension(dimension, business_idea, sector_context)\n",
    "            if evaluation:\n",
    "                evaluations.append(evaluation)\n",
    "        \n",
    "        print()  # Blank line for readability\n",
    "    \n",
    "    return evaluations\n",
    "\n",
    "\n",
    "print(\"âœ“ Agent 3 dimensional evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT 3: DIMENSIONAL EVALUATION\n",
      "================================================================================\n",
      "\n",
      "Evaluating IDEA #1 across 11 dimensions...\n",
      "\n",
      "ğŸ¤– Agent 3.1: Evaluating 'Market Potential' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_1_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-23.json\n",
      "\n",
      "ğŸ¤– Agent 3.2: Evaluating 'Differentiated Approach and Positioning' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_2_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-26.json\n",
      "\n",
      "ğŸ¤– Agent 3.3: Evaluating 'Sustainable Competitive Advantage' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_3_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-28.json\n",
      "\n",
      "ğŸ¤– Agent 3.4: Evaluating 'Differentiating Element' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_4_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-30.json\n",
      "\n",
      "ğŸ¤– Agent 3.5: Evaluating 'Technical Feasibility' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_5_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-33.json\n",
      "\n",
      "ğŸ¤– Agent 3.6: Evaluating 'Affordable & Rapid Implementation' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 7.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_6_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-36.json\n",
      "\n",
      "ğŸ¤– Agent 3.7: Evaluating 'AI Enablement for Core Value' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_7_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-38.json\n",
      "\n",
      "ğŸ¤– Agent 3.8: Evaluating 'Barrier to Entry' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 7.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_8_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-40.json\n",
      "\n",
      "ğŸ¤– Agent 3.9: Evaluating 'Scalable Technology & Operations' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_9_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-43.json\n",
      "\n",
      "ğŸ¤– Agent 3.10: Evaluating 'Product-Focused Output' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 8.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_10_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-45.json\n",
      "\n",
      "ğŸ¤– Agent 3.11: Evaluating 'Subscription-Based Platform Access' using ANTHROPIC...\n",
      "âœ“ Evaluation complete - Score: 7.0/10\n",
      "ğŸ’¾ Checkpoint saved: agent3_11_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-52-48.json\n",
      "\n",
      "================================================================================\n",
      "DIMENSIONAL EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 1: Market Potential\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 8/10\n",
      "\n",
      "**Justification:**\n",
      "The business idea of a Mobility Data Marketplace has strong potential in the European market. The market context highlights significant opportunities, with over 80% of the European population having access to mobile internet and data consumption forecast to triple by 2028. Additionally, less than 1% of freight transport operations within the EU are completely paperless, indicating a clear need for improved data accessibility and integration.\n",
      "\n",
      "The identified market opportunities, such as accelerating multimodal integration projects, facilitating the monetization of data, and transforming the rail sector towards a more digitalized and interoperable system, demonstrate the strong demand for a comprehensive data exchange platform. The business idea's focus on addressing the fragmentation of mobility data and lack of interoperability between systems aligns well with these market needs.\n",
      "\n",
      "However, the market challenges, including resistance from organizations to share proprietary data and ambiguity in calculating the value of data, pose potential risks that the business idea will need to navigate. The implementation path and growth potential outlined in the business idea suggest that the team has a clear strategy to overcome these challenges and capitalize on the significant market opportunity.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 2: Differentiated Approach and Positioning\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score: 8/10**\n",
      "\n",
      "**Justification:**\n",
      "The Mobility Data Marketplace business idea presents a strong and differentiated approach to addressing the fragmentation and lack of interoperability in the European mobility data landscape. The core offering of a secure, trusted platform that facilitates the seamless exchange of mobility data between public and private stakeholders is immediately understandable and fills a clear gap in the market.\n",
      "\n",
      "The business idea targets a niche that is currently underserved, as evidenced by the low percentage of freight transport operations that are completely paperless and the growing demand for data-driven mobility services. The platform's positioning as a neutral, trusted intermediary that enables transparent data governance and revenue sharing mechanisms is a defensible and unique angle compared to alternative solutions.\n",
      "\n",
      "The business's differentiation is further strengthened by its comprehensive data management framework, advanced analytics capabilities, and blockchain-based data exchange technology. These features position the Mobility Data Marketplace as a comprehensive and innovative solution that can unlock new revenue streams and accelerate the development of integrated mobility services across Europe.\n",
      "\n",
      "While the business idea faces some challenges in overcoming data sharing resistance and aligning with varying data regulations across Member States, the strong focus on industry partnerships, regulatory compliance, and a robust data governance model suggest a well-considered approach to addressing these barriers. Overall, the Mobility Data Marketplace presents a compelling and differentiated offering that can drive significant value in the European mobility ecosystem.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 3: Sustainable Competitive Advantage\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 8/10\n",
      "\n",
      "**Justification:**\n",
      "The mobility data marketplace business idea demonstrates strong potential for sustainable competitive advantage. The platform's role as a neutral, trusted intermediary for mobility data exchange is a key strength that addresses the market's fragmentation and lack of interoperability. By providing a comprehensive data management framework, transparent governance, and advanced features like blockchain-based data exchange and AI-powered data valuation, the platform creates significant barriers to entry for potential competitors.\n",
      "\n",
      "The network effects generated as more data owners and consumers join the platform further reinforce its competitive position. Additionally, the platform's ability to continuously invest in expanding its data sources, analytics capabilities, and value-added services suggests that its advantage can improve over time. The business model's reliance on commission-based revenue sharing and subscription fees also indicates a sustainable, compounding revenue stream.\n",
      "\n",
      "However, the platform's success is contingent on overcoming the challenge of aligning with varying data regulations across different European markets, as well as securing the initial critical mass of participants. Mitigating these risks through strategic partnerships and a phased rollout approach will be crucial to solidifying the platform's long-term competitive advantage.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 4: Differentiating Element\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score: 8/10**\n",
      "\n",
      "**Justification:**\n",
      "The key differentiating element of this mobility data marketplace business idea is its comprehensive data management framework and neutral, trusted intermediary role. By providing a secure, cloud-based platform that facilitates the seamless exchange of mobility data between diverse public and private sector stakeholders, the business addresses a critical gap in the fragmented mobility data landscape. \n",
      "\n",
      "The solution's core features, including standardized data formats, trusted data access controls, revenue sharing mechanisms, and advanced analytics tools, directly address the key market challenges of interoperability and data monetization. The use of blockchain-based data exchange and AI-powered data valuation further strengthens the platform's capabilities, positioning it as a trusted and transparent data trading environment.\n",
      "\n",
      "The business's strong focus on data governance expertise, established industry partnerships, and regulatory compliance creates significant barriers to entry, reinforcing its differentiation in the market. The potential for network effects, ongoing investment in platform capabilities, and the ability to expand into adjacent mobility verticals further enhance the sustainability and growth potential of this differentiating approach.\n",
      "\n",
      "While the business faces some challenges in overcoming data sharing resistance and aligning with varying data regulations across Member States, the comprehensive data management framework and neutral intermediary role are clear strengths that position this mobility data marketplace as a leading solution in the European mobility ecosystem.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 5: Technical Feasibility\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 8/10\n",
      "\n",
      "**Justification:**\n",
      "The proposed Mobility Data Marketplace business idea appears to be technically feasible with a strong foundation. The core concept of a secure, cloud-based platform that facilitates the trading of mobility data between stakeholders is well-aligned with the identified market needs and growth drivers. The use of blockchain-based data exchange, AI-powered data valuation, and cloud-native architecture suggests a technologically advanced and scalable approach.\n",
      "\n",
      "The key strengths of this idea from a technical feasibility perspective include the leveraging of established technologies (e.g., cloud, blockchain, AI) to address the complex challenges of data fragmentation and interoperability. The comprehensive data management framework and trusted intermediary role also indicate a well-considered technical strategy. Additionally, the emphasis on standardized data formats and advanced analytics tools suggests a strong focus on enabling seamless data exchange and value-added services.\n",
      "\n",
      "However, the idea does present some technical challenges, such as the need for extensive data integration expertise, secure data access controls, and alignment with varying data regulations across Member States. Overcoming these challenges will require significant technical capabilities and industry partnerships. Additionally, securing the initial critical mass of participants and driving widespread adoption could pose some technical risks, as the platform's success is heavily dependent on network effects.\n",
      "\n",
      "Overall, the Mobility Data Marketplace business idea demonstrates a solid technical foundation and a well-thought-out approach to addressing the identified market needs. With the right technical expertise, industry partnerships, and execution strategy, this idea has the potential to be a technically feasible and scalable solution for the European mobility ecosystem.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 6: Affordable & Rapid Implementation\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 7/10\n",
      "\n",
      "**Justification:**\n",
      "The mobility data marketplace business idea has several strengths in terms of affordable and rapid implementation. The core platform leverages cloud-native architecture and emerging technologies like blockchain, which can enable a relatively quick and cost-effective development of a minimum viable product (MVP). The modular, platform-based approach also allows for iterative development and scaling, rather than a large, upfront investment.\n",
      "\n",
      "Additionally, the business can leverage existing industry partnerships and data integration expertise to accelerate the onboarding of data owners and consumers, which is critical for establishing the initial network effects and critical mass. The neutral, trusted intermediary role of the platform can also help overcome some of the data sharing resistance from organizations, further facilitating rapid adoption.\n",
      "\n",
      "However, the business does face some challenges in this dimension. Aligning with varying data regulations across EU member states and securing the initial participation of a diverse set of stakeholders may require significant upfront effort and investment. The complex data governance frameworks and need for robust data security measures could also add to the implementation complexity and costs. Overall, the business idea shows strong potential for affordable and rapid implementation, but will need to carefully manage the regulatory and stakeholder alignment aspects to fully realize this advantage.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 7: AI Enablement for Core Value\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score: 8/10**\n",
      "\n",
      "**Justification:**\n",
      "The Mobility Data Marketplace business idea demonstrates strong AI enablement for its core value proposition. The platform leverages AI-powered data valuation and advanced analytics tools to facilitate the seamless exchange of mobility data between public and private sector stakeholders. This AI-driven approach is central to the platform's ability to unlock new revenue streams and accelerate the development of innovative mobility services.\n",
      "\n",
      "The use of AI is not superficial but rather a core component that enhances the platform's key functionalities. The AI-powered data valuation and analytics capabilities enable the platform to provide more accurate and dynamic pricing for data transactions, as well as offer value-added services that leverage data insights. This aligns with the first key evaluation question, as the AI capabilities directly improve the platform's outcomes, scale, and cost structure.\n",
      "\n",
      "Furthermore, the AI-driven features are not easily replaceable, as they are integral to the platform's data management framework and data exchange mechanisms. As the platform onboards more data sources and users, the AI-powered analytics are expected to improve in performance, addressing the third key evaluation question. Overall, the Mobility Data Marketplace demonstrates a strong integration of AI that is central to its core value proposition, making it a viable and promising business idea in this dimension.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 8: Barrier to Entry\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score: 7/10**\n",
      "\n",
      "**Justification:**\n",
      "The mobility data marketplace business idea has several strong elements that contribute to a relatively high barrier to entry. Firstly, the concept requires extensive data governance expertise, established industry partnerships, and regulatory compliance - all of which create significant challenges for new entrants. The platform's role as a neutral, trusted intermediary for diverse mobility data stakeholders is also a key differentiator that would be difficult for competitors to replicate.\n",
      "\n",
      "Additionally, the business model's reliance on network effects and ongoing investment in platform capabilities suggests a sustainable competitive advantage. The need for specialized technical capabilities in areas like blockchain, cloud infrastructure, and AI-powered data valuation further raises the bar for potential competitors.\n",
      "\n",
      "However, the business does face some challenges in this dimension. Overcoming data sharing resistance from organizations and aligning with varying data regulations across EU member states could require significant time and resources. Securing the initial critical mass of participants is also a key hurdle that new entrants may be able to more easily overcome. Overall, the business idea demonstrates strong barriers to entry, but there are still some manageable challenges that prevent it from being considered exceptional in this dimension.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 9: Scalable Technology & Operations\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 8/10\n",
      "\n",
      "**Justification:**\n",
      "The mobility data marketplace business idea demonstrates strong potential for scalable technology and operations. The core platform is designed to be cloud-based and leverages emerging technologies like blockchain and AI, which can enable the system to handle significant increases in data volumes and user activity without proportional increases in costs.\n",
      "\n",
      "The key strengths of this idea in the Scalable Technology & Operations dimension are:\n",
      "1. The ability to onboard new data sources and expand into adjacent mobility verticals, indicating strong scalability potential.\n",
      "2. The use of standardized data formats, trusted data access controls, and an automated revenue sharing mechanism, which suggest a high degree of automation and minimal human effort required for onboarding and operations.\n",
      "3. The cloud-native architecture and advanced analytics capabilities, which can enable the platform to handle 10x or 100x increases in users and data without significant marginal cost increases.\n",
      "\n",
      "The primary challenge is the need to overcome data sharing resistance from organizations and align with varying data regulations across EU member states. Addressing these barriers will be critical to ensuring the platform can achieve the desired network effects and scale efficiently. Overall, the business idea presents a compelling vision for a scalable, technology-driven mobility data exchange platform.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 10: Product-Focused Output\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score:** 8/10\n",
      "\n",
      "**Justification:**\n",
      "The mobility data marketplace business idea demonstrates strong product-focused characteristics. The core offering is a secure, cloud-based platform that facilitates the seamless exchange of mobility data between public and private sector stakeholders, which aligns well with the key evaluation questions.\n",
      "\n",
      "The solution is software-driven, with minimal customization required for customers to self-serve and access the marketplace. The platform leverages advanced technologies like blockchain and AI to enable standardized data formats, trusted data access controls, and dynamic pricing - all of which contribute to the repeatability and scalability of the product-focused output.\n",
      "\n",
      "The business model also emphasizes commission-based revenue sharing on data transactions and subscription fees for value-added services, further reinforcing the product-centric nature of the offering. The strong growth potential, with plans to expand into adjacent mobility verticals and offer new data-driven services, further solidifies the product-focused orientation of this business idea.\n",
      "\n",
      "The main area of potential concern is the need to overcome data sharing resistance from organizations and align with varying data regulations across Member States, which could introduce some service-oriented dependencies. However, the comprehensive data governance framework and neutral, trusted intermediary role of the platform help mitigate these challenges, allowing the business to maintain a strong product-focused approach.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "DIMENSION 11: Subscription-Based Platform Access\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "**Score: 7/10**\n",
      "\n",
      "**Justification:**\n",
      "The business idea of a Mobility Data Marketplace has strong potential for a subscription-based platform access model. The concept of facilitating the seamless exchange of mobility data between public and private sector stakeholders aligns well with the key evaluation questions for this dimension.\n",
      "\n",
      "Firstly, the subscription model is a natural fit for this platform, as data owners and consumers will likely require ongoing, reliable access to the marketplace to derive value from the data exchange. The platform's core offering of standardized data formats, trusted data access controls, and revenue sharing mechanisms provides the necessary ongoing value to justify renewal.\n",
      "\n",
      "Secondly, the platform's role as a neutral, trusted intermediary and its comprehensive data management framework can help increase switching costs over time. As data owners and consumers become integrated with the platform's processes and infrastructure, the effort required to migrate to an alternative solution would likely increase, further strengthening the subscription-based model.\n",
      "\n",
      "However, the business idea does face some challenges in this dimension. The resistance from organizations to share proprietary data and the ambiguity in calculating the value of data could present obstacles in driving widespread adoption and retention of the platform's subscription-based services. Overcoming these challenges and ensuring a critical mass of participants will be crucial for the long-term success of the subscription-based platform access model.\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "âœ“ Completed evaluation across 11 dimensions\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENT 3 - ALL 11 DIMENSIONAL EVALUATIONS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AGENT 3: DIMENSIONAL EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if ideas_result and extraction_result:\n",
    "    # Parse the first idea from Agent 2 output\n",
    "    individual_ideas = parse_ideas(ideas_result[\"raw_output\"])\n",
    "    \n",
    "    if individual_ideas:\n",
    "        # Evaluate first idea across all 11 dimensions\n",
    "        first_idea = individual_ideas[0]\n",
    "        print(f\"\\nEvaluating IDEA #1 across {len(DIMENSIONS)} dimensions...\\n\")\n",
    "        \n",
    "        dimensional_evaluations = evaluate_all_dimensions(\n",
    "            business_idea=first_idea,\n",
    "            sector_context=extraction_result[\"raw_output\"]\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(\"=\"*80)\n",
    "        print(\"DIMENSIONAL EVALUATION RESULTS\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for eval_result in dimensional_evaluations:\n",
    "            print(f\"\\n{'â”€'*80}\")\n",
    "            print(f\"DIMENSION {eval_result['dimension_id']}: {eval_result['dimension_name']}\")\n",
    "            print(f\"{'â”€'*80}\")\n",
    "            print(eval_result[\"raw_output\"])\n",
    "            print(f\"{'â”€'*80}\")\n",
    "        \n",
    "        print(f\"\\nâœ“ Completed evaluation across {len(dimensional_evaluations)} dimensions\")\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"âŒ Could not parse ideas from Agent 2 output\")\n",
    "        dimensional_evaluations = []\n",
    "else:\n",
    "    print(\"âŒ Cannot run Agent 3: Missing results from Agent 1 or Agent 2\")\n",
    "    dimensional_evaluations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AGENT 4: Specialized Synthesis Sub-Agents (4.1, 4.2, 4.3)\n",
    "\n",
    "**Purpose**: Generate specific components of the final assessment through focused, specialized agents\n",
    "\n",
    "**Architecture**: Three specialized sub-agents, each with dedicated checkpointing:\n",
    "\n",
    "### **Agent 4.1: Business Idea Summary Generator**\n",
    "- **Input**: Business idea from Agent 2 + dimensional scores from Agent 3.1-3.11\n",
    "- **Output**: Comprehensive 2-4 sentence business concept summary\n",
    "- **Focus**: Core value proposition, target market, key differentiators\n",
    "- **Checkpoint**: `agent4_1_*.json`\n",
    "- **Temperature**: 0.5 (balanced synthesis)\n",
    "\n",
    "### **Agent 4.2: Key Strengths Identifier**\n",
    "- **Input**: Business summary from Agent 4.1 + dimensional scores from Agent 3.1-3.11\n",
    "- **Output**: Top 3 strengths with detailed justifications\n",
    "- **Focus**: Highest scoring dimensions and their strategic implications\n",
    "- **Checkpoint**: `agent4_2_*.json`\n",
    "- **Temperature**: 0.4 (focused analysis)\n",
    "\n",
    "### **Agent 4.3: Key Concerns Identifier**\n",
    "- **Input**: Business summary from Agent 4.1 + dimensional scores from Agent 3.1-3.11\n",
    "- **Output**: Top 3 concerns with mitigation considerations\n",
    "- **Focus**: Lowest scoring dimensions and risk areas\n",
    "- **Checkpoint**: `agent4_3_*.json`\n",
    "- **Temperature**: 0.4 (focused analysis)\n",
    "\n",
    "**Why This Architecture**:\n",
    "- âœ… **Focused Generation**: Each agent has a single, clear responsibility\n",
    "- âœ… **Better Quality**: Specialized prompts produce more accurate outputs\n",
    "- âœ… **Checkpoint Control**: Resume or re-run individual components independently\n",
    "- âœ… **Debugging**: Easy to identify which component failed if issues occur\n",
    "- âœ… **Iterative Refinement**: Test different prompts for each component without re-running everything\n",
    "\n",
    "**Provider**: Works with any configured LLM provider (Ollama/Groq/Anthropic/OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent 4 sub-agent functions defined (4.1: Summary, 4.2: Strengths, 4.3: Concerns)\n"
     ]
    }
   ],
   "source": [
    "# AGENT 4: IMPLEMENTATION - THREE SPECIALIZED SUB-AGENTS\n",
    "\n",
    "def load_all_dimensional_evaluations() -> List[Dict]:\n",
    "    \"\"\"Load all 11 dimensional evaluation checkpoints.\"\"\"\n",
    "    evaluations = []\n",
    "    \n",
    "    for i in range(1, 12):\n",
    "        checkpoint_name = f\"agent3_{i}\"\n",
    "        eval_data = load_checkpoint(checkpoint_name)\n",
    "        \n",
    "        if eval_data:\n",
    "            evaluations.append(eval_data)\n",
    "        else:\n",
    "            print(f\"âš ï¸  Warning: Missing checkpoint for dimension {i}\")\n",
    "    \n",
    "    return evaluations\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# AGENT 4.1: BUSINESS IDEA SUMMARY GENERATOR\n",
    "# ============================================================================\n",
    "\n",
    "AGENT4_1_SYSTEM_PROMPT = \"\"\"You are a business analyst specialized in creating concise, comprehensive business summaries.\n",
    "\n",
    "Your task is to synthesize a business idea into a clear 2-4 sentence summary that captures:\n",
    "1. The core business concept and what it does\n",
    "2. The target customer segment and market\n",
    "3. The primary value proposition\n",
    "\n",
    "Use the dimensional scores to understand strengths and positioning, but focus on creating a clear, compelling summary.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Write 2-4 sentences that flow naturally. Do NOT use bullet points or headers. Just write the summary as a cohesive paragraph.\n",
    "\n",
    "Example output:\n",
    "\"The platform provides integrated mobility-as-a-service for mid-sized cities, combining public transit, ride-sharing, and micromobility into a single app. It targets urban commuters and residents who currently struggle with fragmented transportation options across 3-5 different apps. The solution offers real-time journey planning, unified payment, and AI-powered route optimization, creating a seamless multimodal transportation experience.\"\n",
    "\"\"\"\n",
    "\n",
    "AGENT4_1_USER_PROMPT = \"\"\"Based on the business idea and dimensional evaluation scores, create a comprehensive 2-4 sentence summary.\n",
    "\n",
    "BUSINESS IDEA:\n",
    "---\n",
    "{business_idea}\n",
    "---\n",
    "\n",
    "DIMENSIONAL SCORES:\n",
    "{dim_scores}\n",
    "\n",
    "Write a clear, cohesive 2-4 sentence summary of this business concept. Focus on: what it is, who it serves, and why it matters.\"\"\"\n",
    "\n",
    "\n",
    "def generate_business_summary(business_idea: str, evaluations: List[Dict]) -> str:\n",
    "    \"\"\"\n",
    "    Agent 4.1: Generate business idea summary.\n",
    "    \n",
    "    Args:\n",
    "        business_idea: Original business idea from Agent 2\n",
    "        evaluations: List of dimensional evaluations\n",
    "        \n",
    "    Returns:\n",
    "        str: Business summary (2-4 sentences)\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 4.1: Generating business summary using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Check checkpoint first\n",
    "        cached_result = load_checkpoint(\"agent4_1\")\n",
    "        if cached_result:\n",
    "            print(\"âœ“ Using cached business summary\")\n",
    "            return cached_result.get(\"summary\", \"\")\n",
    "        \n",
    "        # Prepare dimensional scores text\n",
    "        dim_scores_text = \"\\n\".join([\n",
    "            f\"- {e['dimension_name']}: {e['score']}/10\"\n",
    "            for e in sorted(evaluations, key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "        ])\n",
    "        \n",
    "        # Create LLM and prompt\n",
    "        llm = create_llm(temperature=0.5)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", AGENT4_1_SYSTEM_PROMPT),\n",
    "            (\"user\", AGENT4_1_USER_PROMPT)\n",
    "        ])\n",
    "        \n",
    "        messages = prompt.format_messages(\n",
    "            business_idea=business_idea,\n",
    "            dim_scores=dim_scores_text\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        summary = response.content.strip()\n",
    "        \n",
    "        print(f\"âœ“ Summary generated ({len(summary)} characters)\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        result = {\"summary\": summary}\n",
    "        save_checkpoint(\"agent4_1\", result)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error generating summary: {str(e)}\")\n",
    "        return \"Summary generation failed\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# AGENT 4.2: KEY STRENGTHS IDENTIFIER\n",
    "# ============================================================================\n",
    "\n",
    "AGENT4_2_SYSTEM_PROMPT = \"\"\"You are a business analyst specialized in identifying strategic strengths.\n",
    "\n",
    "Your task is to identify the top 3 strengths of a business idea based on dimensional evaluation scores.\n",
    "\n",
    "For each strength, provide:\n",
    "- The dimension name and score\n",
    "- Why this strength is significant\n",
    "- How it contributes to business success\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return exactly 3 bullet points in this format:\n",
    "\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining why this is a strength and how it contributes to success]\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining why this is a strength and how it contributes to success]\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining why this is a strength and how it contributes to success]\n",
    "\n",
    "Focus on the highest-scoring dimensions and their strategic implications.\"\"\"\n",
    "\n",
    "AGENT4_2_USER_PROMPT = \"\"\"Identify the top 3 strengths for this business idea based on the dimensional scores.\n",
    "\n",
    "BUSINESS SUMMARY:\n",
    "{business_summary}\n",
    "\n",
    "DIMENSIONAL EVALUATIONS (sorted by score):\n",
    "{dim_evaluations}\n",
    "\n",
    "Return exactly 3 bullet points highlighting the top strengths.\"\"\"\n",
    "\n",
    "\n",
    "def identify_key_strengths(business_summary: str, evaluations: List[Dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Agent 4.2: Identify top 3 key strengths.\n",
    "    \n",
    "    Args:\n",
    "        business_summary: Summary from Agent 4.1\n",
    "        evaluations: List of dimensional evaluations\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Top 3 strengths\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 4.2: Identifying key strengths using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Check checkpoint first\n",
    "        cached_result = load_checkpoint(\"agent4_2\")\n",
    "        if cached_result:\n",
    "            print(\"âœ“ Using cached key strengths\")\n",
    "            return cached_result.get(\"strengths\", [])\n",
    "        \n",
    "        # Sort evaluations by score (highest first)\n",
    "        sorted_evals = sorted(evaluations, key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "        \n",
    "        # Prepare dimensional evaluations text with justifications\n",
    "        dim_evals_text = \"\\n\\n\".join([\n",
    "            f\"{e['dimension_name']}: {e['score']}/10\\n{e.get('raw_output', '')}\"\n",
    "            for e in sorted_evals[:5]  # Top 5 for context\n",
    "        ])\n",
    "        \n",
    "        # Create LLM and prompt\n",
    "        llm = create_llm(temperature=0.4)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", AGENT4_2_SYSTEM_PROMPT),\n",
    "            (\"user\", AGENT4_2_USER_PROMPT)\n",
    "        ])\n",
    "        \n",
    "        messages = prompt.format_messages(\n",
    "            business_summary=business_summary,\n",
    "            dim_evaluations=dim_evals_text\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        output = response.content.strip()\n",
    "        \n",
    "        # Parse bullet points\n",
    "        strengths = []\n",
    "        for line in output.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('- **') or line.startswith('* **') or line.startswith('â€¢ **'):\n",
    "                # Remove leading bullet\n",
    "                clean_line = re.sub(r'^[-*â€¢]\\s*', '', line)\n",
    "                strengths.append(clean_line)\n",
    "        \n",
    "        # Ensure we have exactly 3\n",
    "        strengths = strengths[:3]\n",
    "        \n",
    "        # Fallback if parsing failed\n",
    "        if len(strengths) < 3:\n",
    "            top_3 = sorted_evals[:3]\n",
    "            strengths = [\n",
    "                f\"**{e['dimension_name']} ({e['score']}/10):** This dimension scored highly, indicating strong potential in this area.\"\n",
    "                for e in top_3\n",
    "            ]\n",
    "        \n",
    "        print(f\"âœ“ Identified {len(strengths)} key strengths\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        result = {\"strengths\": strengths}\n",
    "        save_checkpoint(\"agent4_2\", result)\n",
    "        \n",
    "        return strengths\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error identifying strengths: {str(e)}\")\n",
    "        # Fallback\n",
    "        top_3 = sorted(evaluations, key=lambda x: x.get(\"score\", 0), reverse=True)[:3]\n",
    "        return [\n",
    "            f\"**{e['dimension_name']} ({e['score']}/10):** Strong performance in this dimension.\"\n",
    "            for e in top_3\n",
    "        ]\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# AGENT 4.3: KEY CONCERNS IDENTIFIER\n",
    "# ============================================================================\n",
    "\n",
    "AGENT4_3_SYSTEM_PROMPT = \"\"\"You are a business analyst specialized in identifying risks and concerns.\n",
    "\n",
    "Your task is to identify the top 3 concerns for a business idea based on dimensional evaluation scores.\n",
    "\n",
    "For each concern, provide:\n",
    "- The dimension name and score\n",
    "- Why this score indicates a concern\n",
    "- What risks or challenges this presents\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return exactly 3 bullet points in this format:\n",
    "\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining the concern and its implications]\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining the concern and its implications]\n",
    "- **[Dimension Name] ([Score]/10):** [2-3 sentences explaining the concern and its implications]\n",
    "\n",
    "Focus on the lowest-scoring dimensions and their risk implications.\"\"\"\n",
    "\n",
    "AGENT4_3_USER_PROMPT = \"\"\"Identify the top 3 concerns for this business idea based on the dimensional scores.\n",
    "\n",
    "BUSINESS SUMMARY:\n",
    "{business_summary}\n",
    "\n",
    "DIMENSIONAL EVALUATIONS (sorted by score, lowest first):\n",
    "{dim_evaluations}\n",
    "\n",
    "Return exactly 3 bullet points highlighting the top concerns.\"\"\"\n",
    "\n",
    "\n",
    "def identify_key_concerns(business_summary: str, evaluations: List[Dict]) -> List[str]:\n",
    "    \"\"\"\n",
    "    Agent 4.3: Identify top 3 key concerns.\n",
    "    \n",
    "    Args:\n",
    "        business_summary: Summary from Agent 4.1\n",
    "        evaluations: List of dimensional evaluations\n",
    "        \n",
    "    Returns:\n",
    "        List[str]: Top 3 concerns\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 4.3: Identifying key concerns using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Check checkpoint first\n",
    "        cached_result = load_checkpoint(\"agent4_3\")\n",
    "        if cached_result:\n",
    "            print(\"âœ“ Using cached key concerns\")\n",
    "            return cached_result.get(\"concerns\", [])\n",
    "        \n",
    "        # Sort evaluations by score (lowest first)\n",
    "        sorted_evals = sorted(evaluations, key=lambda x: x.get(\"score\", 0))\n",
    "        \n",
    "        # Prepare dimensional evaluations text with justifications\n",
    "        dim_evals_text = \"\\n\\n\".join([\n",
    "            f\"{e['dimension_name']}: {e['score']}/10\\n{e.get('raw_output', '')}\"\n",
    "            for e in sorted_evals[:5]  # Bottom 5 for context\n",
    "        ])\n",
    "        \n",
    "        # Create LLM and prompt\n",
    "        llm = create_llm(temperature=0.4)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", AGENT4_3_SYSTEM_PROMPT),\n",
    "            (\"user\", AGENT4_3_USER_PROMPT)\n",
    "        ])\n",
    "        \n",
    "        messages = prompt.format_messages(\n",
    "            business_summary=business_summary,\n",
    "            dim_evaluations=dim_evals_text\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        output = response.content.strip()\n",
    "        \n",
    "        # Parse bullet points\n",
    "        concerns = []\n",
    "        for line in output.split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line.startswith('- **') or line.startswith('* **') or line.startswith('â€¢ **'):\n",
    "                # Remove leading bullet\n",
    "                clean_line = re.sub(r'^[-*â€¢]\\s*', '', line)\n",
    "                concerns.append(clean_line)\n",
    "        \n",
    "        # Ensure we have exactly 3\n",
    "        concerns = concerns[:3]\n",
    "        \n",
    "        # Fallback if parsing failed\n",
    "        if len(concerns) < 3:\n",
    "            bottom_3 = sorted_evals[:3]\n",
    "            concerns = [\n",
    "                f\"**{e['dimension_name']} ({e['score']}/10):** This dimension scored lower, indicating an area requiring attention.\"\n",
    "                for e in bottom_3\n",
    "            ]\n",
    "        \n",
    "        print(f\"âœ“ Identified {len(concerns)} key concerns\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        result = {\"concerns\": concerns}\n",
    "        save_checkpoint(\"agent4_3\", result)\n",
    "        \n",
    "        return concerns\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error identifying concerns: {str(e)}\")\n",
    "        # Fallback\n",
    "        bottom_3 = sorted(evaluations, key=lambda x: x.get(\"score\", 0))[:3]\n",
    "        return [\n",
    "            f\"**{e['dimension_name']} ({e['score']}/10):** Lower score indicates potential challenges.\"\n",
    "            for e in bottom_3\n",
    "        ]\n",
    "\n",
    "\n",
    "print(\"âœ“ Agent 4 sub-agent functions defined (4.1: Summary, 4.2: Strengths, 4.3: Concerns)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT 4: SPECIALIZED SYNTHESIS SUB-AGENTS\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– Agent 4.1: Generating business summary using ANTHROPIC...\n",
      "âœ“ Summary generated (749 characters)\n",
      "ğŸ’¾ Checkpoint saved: agent4_1_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-53-45.json\n",
      "\n",
      "ğŸ¤– Agent 4.2: Identifying key strengths using ANTHROPIC...\n",
      "âœ“ Identified 3 key strengths\n",
      "ğŸ’¾ Checkpoint saved: agent4_2_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-53-48.json\n",
      "\n",
      "ğŸ¤– Agent 4.3: Identifying key concerns using ANTHROPIC...\n",
      "âœ“ Identified 3 key concerns\n",
      "ğŸ’¾ Checkpoint saved: agent4_3_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-53-51.json\n",
      "\n",
      "================================================================================\n",
      "AGENT 4 SYNTHESIS RESULTS\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ BUSINESS SUMMARY (Agent 4.1):\n",
      "--------------------------------------------------------------------------------\n",
      "The Mobility Data Marketplace is a secure, trusted platform that enables the seamless exchange of mobility data between public and private sector stakeholders, unlocking new revenue streams and accelerating the development of innovative mobility services. Targeting the growing demand for data-driven mobility solutions, the platform provides a comprehensive data management framework, transparent governance, and a neutral, trusted intermediary role to facilitate the trading of mobility data across the European ecosystem. By overcoming fragmentation and lack of interoperability, the Mobility Data Marketplace empowers stakeholders to unlock the full potential of mobility data and drive the transformation towards sustainable and smart mobility.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ… KEY STRENGTHS (Agent 4.2):\n",
      "--------------------------------------------------------------------------------\n",
      "1. **Market Potential (8/10):** The business idea has strong potential in the European market, with significant opportunities driven by the growing demand for data-driven mobility solutions, the low level of digitalization in freight transport, and the need for improved data accessibility and integration. The identified market opportunities, such as accelerating multimodal integration projects and facilitating the monetization of data, demonstrate the strong demand for a comprehensive data exchange platform.\n",
      "\n",
      "2. **Differentiated Approach and Positioning (8/10):** The Mobility Data Marketplace presents a unique and differentiated approach to addressing the fragmentation and lack of interoperability in the European mobility data landscape. The core offering of a secure, trusted platform that facilitates the seamless exchange of mobility data between public and private stakeholders fills a clear gap in the market. The platform's positioning as a neutral, trusted intermediary with a comprehensive data management framework and advanced features, such as blockchain-based data exchange and AI-powered data valuation, creates a defensible and compelling value proposition.\n",
      "\n",
      "3. **Sustainable Competitive Advantage (8/10):** The business idea demonstrates strong potential for sustainable competitive advantage. The platform's role as a neutral, trusted intermediary for mobility data exchange, its comprehensive data management framework, and advanced features create significant barriers to entry for potential competitors. The network effects generated as more participants join the platform, the ability to continuously invest in expanding its capabilities, and the sustainable revenue model further reinforce the platform's long-term competitive position.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âš ï¸  KEY CONCERNS (Agent 4.3):\n",
      "--------------------------------------------------------------------------------\n",
      "1. **Affordable & Rapid Implementation (7/10):** While the core platform leverages cloud-native and emerging technologies, aligning with varying data regulations across EU member states and securing the initial participation of diverse stakeholders may require significant upfront effort and investment. The complex data governance frameworks and need for robust data security measures could also add to the implementation complexity and costs, posing risks to the business's ability to achieve affordable and rapid implementation.\n",
      "\n",
      "2. **Barrier to Entry (7/10):** The business idea demonstrates strong barriers to entry, including the need for extensive data governance expertise, established industry partnerships, and regulatory compliance. However, overcoming data sharing resistance from organizations and aligning with varying data regulations across EU member states could require significant time and resources. Securing the initial critical mass of participants is also a key hurdle that new entrants may be able to more easily overcome, presenting potential challenges to the business's competitive advantage.\n",
      "\n",
      "3. **Subscription-Based Platform Access (7/10):** The subscription-based model is a natural fit for the Mobility Data Marketplace, as data owners and consumers will likely require ongoing, reliable access to the platform. However, the resistance from organizations to share proprietary data and the ambiguity in calculating the value of data could present obstacles in driving widespread adoption and retention of the platform's subscription-based services. Ensuring a critical mass of participants will be crucial for the long-term success of the subscription-based platform access model.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ All Agent 4 sub-agents completed successfully\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENT 4 - THREE SPECIALIZED SUB-AGENTS\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AGENT 4: SPECIALIZED SYNTHESIS SUB-AGENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if we have the necessary inputs\n",
    "if 'dimensional_evaluations' not in locals() or not dimensional_evaluations:\n",
    "    print(\"\\nLoading dimensional evaluations from checkpoints...\")\n",
    "    dimensional_evaluations = load_all_dimensional_evaluations()\n",
    "\n",
    "if 'first_idea' not in locals() and ideas_result:\n",
    "    individual_ideas = parse_ideas(ideas_result[\"raw_output\"])\n",
    "    first_idea = individual_ideas[0] if individual_ideas else None\n",
    "\n",
    "if len(dimensional_evaluations) == 11 and first_idea:\n",
    "    # Run Agent 4.1: Generate Business Summary\n",
    "    business_summary = generate_business_summary(first_idea, dimensional_evaluations)\n",
    "    \n",
    "    # Run Agent 4.2: Identify Key Strengths\n",
    "    key_strengths = identify_key_strengths(business_summary, dimensional_evaluations)\n",
    "    \n",
    "    # Run Agent 4.3: Identify Key Concerns\n",
    "    key_concerns = identify_key_concerns(business_summary, dimensional_evaluations)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AGENT 4 SYNTHESIS RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\nğŸ“ BUSINESS SUMMARY (Agent 4.1):\")\n",
    "    print(\"-\" * 80)\n",
    "    print(business_summary)\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nâœ… KEY STRENGTHS (Agent 4.2):\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, strength in enumerate(key_strengths, 1):\n",
    "        print(f\"{i}. {strength}\")\n",
    "        print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nâš ï¸  KEY CONCERNS (Agent 4.3):\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, concern in enumerate(key_concerns, 1):\n",
    "        print(f\"{i}. {concern}\")\n",
    "        print()\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\nâœ“ All Agent 4 sub-agents completed successfully\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nâŒ Cannot run Agent 4: Missing inputs\")\n",
    "    print(f\"   Dimensional evaluations: {len(dimensional_evaluations) if 'dimensional_evaluations' in locals() else 0}/11\")\n",
    "    print(f\"   Business idea: {'Available' if 'first_idea' in locals() and first_idea else 'Not available'}\")\n",
    "    business_summary = None\n",
    "    key_strengths = []\n",
    "    key_concerns = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## AGENT 5: Final Consolidation and Report Generation\n",
    "\n",
    "**Purpose**: Consolidate all agent outputs into a comprehensive final JSON report\n",
    "\n",
    "**What it does**:\n",
    "- Loads checkpoints from Agent 3.1-3.11 (dimensional scores)\n",
    "- Loads checkpoints from Agent 4.1 (business summary)\n",
    "- Loads checkpoints from Agent 4.2 (key strengths)\n",
    "- Loads checkpoints from Agent 4.3 (key concerns)\n",
    "- Calculates weighted overall score based on dimension weights\n",
    "- Generates final recommendation (STRONG_PROCEED, CONDITIONAL_PROCEED, REQUIRES_REFINEMENT, REJECT)\n",
    "- Creates recommendation rationale using AI\n",
    "- Outputs structured JSON report\n",
    "- Saves report to checkpoint and results file\n",
    "\n",
    "**Weighting System** (configurable, defaults sum to 100%):\n",
    "- Market Potential: 12%\n",
    "- Barrier to Entry: 11%\n",
    "- Differentiated Approach and Positioning: 10%\n",
    "- Sustainable Competitive Advantage: 10%\n",
    "- Affordable & Rapid Implementation: 10%\n",
    "- Technical Feasibility: 9%\n",
    "- Scalable Technology & Operations: 9%\n",
    "- AI Enablement for Core Value: 8%\n",
    "- Differentiating Element: 8%\n",
    "- Product-Focused Output: 7%\n",
    "- Subscription-Based Platform Access: 6%\n",
    "\n",
    "**Recommendation Thresholds**:\n",
    "- 8.0-10.0: STRONG_PROCEED - High confidence, ready to pursue\n",
    "- 6.0-7.9: CONDITIONAL_PROCEED - Promising with some concerns\n",
    "- 4.0-5.9: REQUIRES_REFINEMENT - Needs significant improvements\n",
    "- 0.0-3.9: REJECT - Not recommended\n",
    "\n",
    "**Output Format**: Structured JSON matching the format in checkpoints:\n",
    "```json\n",
    "{\n",
    "  \"business_idea_summary\": \"...\",\n",
    "  \"dimensional_scores\": [...],\n",
    "  \"key_strengths\": [...],\n",
    "  \"key_concerns\": [...],\n",
    "  \"overall_score\": 7.8,\n",
    "  \"recommendation\": \"CONDITIONAL_PROCEED\",\n",
    "  \"recommendation_rationale\": \"...\"\n",
    "}\n",
    "```\n",
    "\n",
    "**Temperature**: 0.5 (balanced - for rationale generation)\n",
    "**Provider**: Works with any configured LLM provider (Ollama/Groq/Anthropic/OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Agent 5 consolidation functions defined\n"
     ]
    }
   ],
   "source": [
    "# AGENT 5: IMPLEMENTATION - FINAL CONSOLIDATION\n",
    "\n",
    "# Dimension weights (must sum to 100%)\n",
    "DIMENSION_WEIGHTS = {\n",
    "    \"Market Potential\": 0.12,\n",
    "    \"Differentiated Approach and Positioning\": 0.10,\n",
    "    \"Sustainable Competitive Advantage\": 0.10,\n",
    "    \"Differentiating Element\": 0.08,\n",
    "    \"Technical Feasibility\": 0.09,\n",
    "    \"Affordable & Rapid Implementation\": 0.10,\n",
    "    \"AI Enablement for Core Value\": 0.08,\n",
    "    \"Barrier to Entry\": 0.11,\n",
    "    \"Scalable Technology & Operations\": 0.09,\n",
    "    \"Product-Focused Output\": 0.07,\n",
    "    \"Subscription-Based Platform Access\": 0.06\n",
    "}\n",
    "\n",
    "\n",
    "def calculate_overall_score(evaluations: List[Dict]) -> float:\n",
    "    \"\"\"Calculate weighted overall score from dimensional evaluations.\"\"\"\n",
    "    weighted_sum = 0.0\n",
    "    \n",
    "    for eval_data in evaluations:\n",
    "        dim_name = eval_data.get(\"dimension_name\")\n",
    "        score = eval_data.get(\"score\", 0)\n",
    "        weight = DIMENSION_WEIGHTS.get(dim_name, 0)\n",
    "        \n",
    "        weighted_sum += score * weight\n",
    "    \n",
    "    return round(weighted_sum, 1)\n",
    "\n",
    "\n",
    "def get_recommendation(overall_score: float) -> str:\n",
    "    \"\"\"Determine recommendation based on overall score.\"\"\"\n",
    "    if overall_score >= 8.0:\n",
    "        return \"STRONG_PROCEED\"\n",
    "    elif overall_score >= 6.0:\n",
    "        return \"CONDITIONAL_PROCEED\"\n",
    "    elif overall_score >= 4.0:\n",
    "        return \"REQUIRES_REFINEMENT\"\n",
    "    else:\n",
    "        return \"REJECT\"\n",
    "\n",
    "\n",
    "AGENT5_RATIONALE_SYSTEM_PROMPT = \"\"\"You are a business analyst writing a final recommendation rationale.\n",
    "\n",
    "Your task is to write a concise 2-3 sentence rationale that:\n",
    "1. Explains why the overall recommendation is appropriate\n",
    "2. References the overall score and key score patterns\n",
    "3. Highlights the most critical factor for decision-making\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Write 2-3 sentences as a cohesive paragraph. No bullet points or headers.\"\"\"\n",
    "\n",
    "AGENT5_RATIONALE_USER_PROMPT = \"\"\"Write a recommendation rationale for this business idea evaluation.\n",
    "\n",
    "OVERALL SCORE: {overall_score}/10\n",
    "RECOMMENDATION: {recommendation}\n",
    "\n",
    "TOP STRENGTHS:\n",
    "{strengths}\n",
    "\n",
    "TOP CONCERNS:\n",
    "{concerns}\n",
    "\n",
    "DIMENSIONAL SCORES:\n",
    "{dim_scores}\n",
    "\n",
    "Write a 2-3 sentence rationale explaining why this recommendation is appropriate.\"\"\"\n",
    "\n",
    "\n",
    "def generate_recommendation_rationale(\n",
    "    overall_score: float, \n",
    "    recommendation: str, \n",
    "    strengths: List[str], \n",
    "    concerns: List[str],\n",
    "    evaluations: List[Dict]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate recommendation rationale using AI.\n",
    "    \n",
    "    Args:\n",
    "        overall_score: Weighted overall score\n",
    "        recommendation: Recommendation tier\n",
    "        strengths: Key strengths from Agent 4.2\n",
    "        concerns: Key concerns from Agent 4.3\n",
    "        evaluations: Dimensional evaluations\n",
    "        \n",
    "    Returns:\n",
    "        str: Recommendation rationale (2-3 sentences)\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 5: Generating recommendation rationale using {PROVIDER.upper()}...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare inputs\n",
    "        strengths_text = \"\\n\".join([f\"- {s}\" for s in strengths])\n",
    "        concerns_text = \"\\n\".join([f\"- {c}\" for c in concerns])\n",
    "        dim_scores_text = \"\\n\".join([\n",
    "            f\"- {e['dimension_name']}: {e['score']}/10\"\n",
    "            for e in sorted(evaluations, key=lambda x: x.get(\"score\", 0), reverse=True)\n",
    "        ])\n",
    "        \n",
    "        # Create LLM and prompt\n",
    "        llm = create_llm(temperature=0.5)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", AGENT5_RATIONALE_SYSTEM_PROMPT),\n",
    "            (\"user\", AGENT5_RATIONALE_USER_PROMPT)\n",
    "        ])\n",
    "        \n",
    "        messages = prompt.format_messages(\n",
    "            overall_score=overall_score,\n",
    "            recommendation=recommendation,\n",
    "            strengths=strengths_text,\n",
    "            concerns=concerns_text,\n",
    "            dim_scores=dim_scores_text\n",
    "        )\n",
    "        \n",
    "        response = llm.invoke(messages)\n",
    "        rationale = response.content.strip()\n",
    "        \n",
    "        print(f\"âœ“ Rationale generated ({len(rationale)} characters)\")\n",
    "        \n",
    "        return rationale\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error generating rationale: {str(e)}\")\n",
    "        # Fallback\n",
    "        return f\"With an overall score of {overall_score}/10, this business idea shows {recommendation.lower().replace('_', ' ')} potential based on the comprehensive evaluation across 11 dimensions.\"\n",
    "\n",
    "\n",
    "def consolidate_final_report(\n",
    "    business_summary: str,\n",
    "    key_strengths: List[str],\n",
    "    key_concerns: List[str],\n",
    "    evaluations: List[Dict]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Agent 5: Consolidate all outputs into final JSON report.\n",
    "    \n",
    "    Args:\n",
    "        business_summary: Summary from Agent 4.1\n",
    "        key_strengths: Strengths from Agent 4.2\n",
    "        key_concerns: Concerns from Agent 4.3\n",
    "        evaluations: Dimensional evaluations from Agent 3.1-3.11\n",
    "        \n",
    "    Returns:\n",
    "        Dict: Final comprehensive report\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ¤– Agent 5: Consolidating final report...\")\n",
    "    \n",
    "    try:\n",
    "        # Check checkpoint first\n",
    "        cached_result = load_checkpoint(\"agent5\")\n",
    "        if cached_result:\n",
    "            print(\"âœ“ Using cached final report\")\n",
    "            return cached_result\n",
    "        \n",
    "        # Calculate overall score\n",
    "        overall_score = calculate_overall_score(evaluations)\n",
    "        recommendation = get_recommendation(overall_score)\n",
    "        \n",
    "        # Generate rationale\n",
    "        rationale = generate_recommendation_rationale(\n",
    "            overall_score, \n",
    "            recommendation, \n",
    "            key_strengths, \n",
    "            key_concerns,\n",
    "            evaluations\n",
    "        )\n",
    "        \n",
    "        # Build final report\n",
    "        final_report = {\n",
    "            \"business_idea_summary\": business_summary,\n",
    "            \"dimensional_scores\": [\n",
    "                {\n",
    "                    \"dimension\": eval_data[\"dimension_name\"],\n",
    "                    \"score\": eval_data[\"score\"]\n",
    "                }\n",
    "                for eval_data in evaluations\n",
    "            ],\n",
    "            \"key_strengths\": key_strengths,\n",
    "            \"key_concerns\": key_concerns,\n",
    "            \"overall_score\": overall_score,\n",
    "            \"recommendation\": recommendation,\n",
    "            \"recommendation_rationale\": rationale\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint\n",
    "        save_checkpoint(\"agent5\", final_report)\n",
    "        \n",
    "        print(\"âœ“ Final report consolidation complete\")\n",
    "        \n",
    "        return final_report\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error consolidating report: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"âœ“ Agent 5 consolidation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGENT 5: FINAL CONSOLIDATION AND REPORT GENERATION\n",
      "================================================================================\n",
      "\n",
      "ğŸ¤– Agent 5: Consolidating final report...\n",
      "\n",
      "ğŸ¤– Agent 5: Generating recommendation rationale using ANTHROPIC...\n",
      "âœ“ Rationale generated (570 characters)\n",
      "ğŸ’¾ Checkpoint saved: agent5_EITUM_MDS-study_long (3)_mobility_2026-02-06_11-54-37.json\n",
      "âœ“ Final report consolidation complete\n",
      "\n",
      "================================================================================\n",
      "FINAL BUSINESS IDEA ASSESSMENT REPORT\n",
      "================================================================================\n",
      "\n",
      "{\n",
      "  \"business_idea_summary\": \"The Mobility Data Marketplace is a secure, trusted platform that enables the seamless exchange of mobility data between public and private sector stakeholders, unlocking new revenue streams and accelerating the development of innovative mobility services. Targeting the growing demand for data-driven mobility solutions, the platform provides a comprehensive data management framework, transparent governance, and a neutral, trusted intermediary role to facilitate the trading of mobility data across the European ecosystem. By overcoming fragmentation and lack of interoperability, the Mobility Data Marketplace empowers stakeholders to unlock the full potential of mobility data and drive the transformation towards sustainable and smart mobility.\",\n",
      "  \"dimensional_scores\": [\n",
      "    {\n",
      "      \"dimension\": \"Market Potential\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Differentiated Approach and Positioning\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Sustainable Competitive Advantage\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Differentiating Element\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Technical Feasibility\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Affordable & Rapid Implementation\",\n",
      "      \"score\": 7.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"AI Enablement for Core Value\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Barrier to Entry\",\n",
      "      \"score\": 7.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Scalable Technology & Operations\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Product-Focused Output\",\n",
      "      \"score\": 8.0\n",
      "    },\n",
      "    {\n",
      "      \"dimension\": \"Subscription-Based Platform Access\",\n",
      "      \"score\": 7.0\n",
      "    }\n",
      "  ],\n",
      "  \"key_strengths\": [\n",
      "    \"**Market Potential (8/10):** The business idea has strong potential in the European market, with significant opportunities driven by the growing demand for data-driven mobility solutions, the low level of digitalization in freight transport, and the need for improved data accessibility and integration. The identified market opportunities, such as accelerating multimodal integration projects and facilitating the monetization of data, demonstrate the strong demand for a comprehensive data exchange platform.\",\n",
      "    \"**Differentiated Approach and Positioning (8/10):** The Mobility Data Marketplace presents a unique and differentiated approach to addressing the fragmentation and lack of interoperability in the European mobility data landscape. The core offering of a secure, trusted platform that facilitates the seamless exchange of mobility data between public and private stakeholders fills a clear gap in the market. The platform's positioning as a neutral, trusted intermediary with a comprehensive data management framework and advanced features, such as blockchain-based data exchange and AI-powered data valuation, creates a defensible and compelling value proposition.\",\n",
      "    \"**Sustainable Competitive Advantage (8/10):** The business idea demonstrates strong potential for sustainable competitive advantage. The platform's role as a neutral, trusted intermediary for mobility data exchange, its comprehensive data management framework, and advanced features create significant barriers to entry for potential competitors. The network effects generated as more participants join the platform, the ability to continuously invest in expanding its capabilities, and the sustainable revenue model further reinforce the platform's long-term competitive position.\"\n",
      "  ],\n",
      "  \"key_concerns\": [\n",
      "    \"**Affordable & Rapid Implementation (7/10):** While the core platform leverages cloud-native and emerging technologies, aligning with varying data regulations across EU member states and securing the initial participation of diverse stakeholders may require significant upfront effort and investment. The complex data governance frameworks and need for robust data security measures could also add to the implementation complexity and costs, posing risks to the business's ability to achieve affordable and rapid implementation.\",\n",
      "    \"**Barrier to Entry (7/10):** The business idea demonstrates strong barriers to entry, including the need for extensive data governance expertise, established industry partnerships, and regulatory compliance. However, overcoming data sharing resistance from organizations and aligning with varying data regulations across EU member states could require significant time and resources. Securing the initial critical mass of participants is also a key hurdle that new entrants may be able to more easily overcome, presenting potential challenges to the business's competitive advantage.\",\n",
      "    \"**Subscription-Based Platform Access (7/10):** The subscription-based model is a natural fit for the Mobility Data Marketplace, as data owners and consumers will likely require ongoing, reliable access to the platform. However, the resistance from organizations to share proprietary data and the ambiguity in calculating the value of data could present obstacles in driving widespread adoption and retention of the platform's subscription-based services. Ensuring a critical mass of participants will be crucial for the long-term success of the subscription-based platform access model.\"\n",
      "  ],\n",
      "  \"overall_score\": 7.7,\n",
      "  \"recommendation\": \"CONDITIONAL_PROCEED\",\n",
      "  \"recommendation_rationale\": \"The overall recommendation to conditionally proceed with the Mobility Data Marketplace business idea is appropriate given the strong scores across key dimensions, including market potential, differentiated approach, and sustainable competitive advantage. While there are some concerns around affordable and rapid implementation, barriers to entry, and the subscription-based platform access model, the business idea demonstrates a compelling value proposition and the potential to become a trusted, neutral intermediary for mobility data exchange in the European market.\"\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "OVERALL SCORE: 7.7/10\n",
      "RECOMMENDATION: CONDITIONAL_PROCEED\n",
      "================================================================================\n",
      "\n",
      "âœ“ Final report saved to: results_mobility_20260206_115437.json\n"
     ]
    }
   ],
   "source": [
    "# RUN AGENT 5 - FINAL CONSOLIDATION AND REPORT GENERATION\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AGENT 5: FINAL CONSOLIDATION AND REPORT GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check if we have all necessary inputs\n",
    "if all([\n",
    "    'business_summary' in locals() and business_summary,\n",
    "    'key_strengths' in locals() and key_strengths,\n",
    "    'key_concerns' in locals() and key_concerns,\n",
    "    'dimensional_evaluations' in locals() and len(dimensional_evaluations) == 11\n",
    "]):\n",
    "    # Run Agent 5: Consolidate final report\n",
    "    final_report = consolidate_final_report(\n",
    "        business_summary,\n",
    "        key_strengths,\n",
    "        key_concerns,\n",
    "        dimensional_evaluations\n",
    "    )\n",
    "    \n",
    "    # Display final report\n",
    "    if final_report:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"FINAL BUSINESS IDEA ASSESSMENT REPORT\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Pretty print the JSON report\n",
    "        print(\"\\n\" + json.dumps(final_report, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"OVERALL SCORE: {final_report['overall_score']}/10\")\n",
    "        print(f\"RECOMMENDATION: {final_report['recommendation']}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Save to file\n",
    "        results_filename = f\"results_{SECTOR}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(results_filename, 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"\\nâœ“ Final report saved to: {results_filename}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Agent 5 failed to produce final report\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\nâŒ Cannot run Agent 5: Missing required inputs\")\n",
    "    \n",
    "    # Load from checkpoints if available\n",
    "    print(\"\\nAttempting to load from checkpoints...\")\n",
    "    \n",
    "    if 'dimensional_evaluations' not in locals() or len(dimensional_evaluations) != 11:\n",
    "        print(\"  Loading dimensional evaluations...\")\n",
    "        dimensional_evaluations = load_all_dimensional_evaluations()\n",
    "    \n",
    "    if 'business_summary' not in locals():\n",
    "        print(\"  Loading business summary from Agent 4.1 checkpoint...\")\n",
    "        agent4_1_data = load_checkpoint(\"agent4_1\")\n",
    "        business_summary = agent4_1_data.get(\"summary\", \"\") if agent4_1_data else None\n",
    "    \n",
    "    if 'key_strengths' not in locals():\n",
    "        print(\"  Loading key strengths from Agent 4.2 checkpoint...\")\n",
    "        agent4_2_data = load_checkpoint(\"agent4_2\")\n",
    "        key_strengths = agent4_2_data.get(\"strengths\", []) if agent4_2_data else []\n",
    "    \n",
    "    if 'key_concerns' not in locals():\n",
    "        print(\"  Loading key concerns from Agent 4.3 checkpoint...\")\n",
    "        agent4_3_data = load_checkpoint(\"agent4_3\")\n",
    "        key_concerns = agent4_3_data.get(\"concerns\", []) if agent4_3_data else []\n",
    "    \n",
    "    # Try again\n",
    "    if all([\n",
    "        business_summary,\n",
    "        key_strengths,\n",
    "        key_concerns,\n",
    "        len(dimensional_evaluations) == 11\n",
    "    ]):\n",
    "        print(\"\\nâœ“ All inputs loaded from checkpoints, running Agent 5...\")\n",
    "        \n",
    "        final_report = consolidate_final_report(\n",
    "            business_summary,\n",
    "            key_strengths,\n",
    "            key_concerns,\n",
    "            dimensional_evaluations\n",
    "        )\n",
    "        \n",
    "        if final_report:\n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(\"FINAL BUSINESS IDEA ASSESSMENT REPORT\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            print(\"\\n\" + json.dumps(final_report, indent=2, ensure_ascii=False))\n",
    "            \n",
    "            print(\"\\n\" + \"=\"*80)\n",
    "            print(f\"OVERALL SCORE: {final_report['overall_score']}/10\")\n",
    "            print(f\"RECOMMENDATION: {final_report['recommendation']}\")\n",
    "            print(\"=\"*80)\n",
    "            \n",
    "            # Save to file\n",
    "            results_filename = f\"results_{SECTOR}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "            with open(results_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_report, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"\\nâœ“ Final report saved to: {results_filename}\")\n",
    "    else:\n",
    "        print(\"\\nâŒ Still missing required inputs:\")\n",
    "        print(f\"  Business summary: {'âœ“' if business_summary else 'âœ—'}\")\n",
    "        print(f\"  Key strengths: {'âœ“' if key_strengths else 'âœ—'}\")\n",
    "        print(f\"  Key concerns: {'âœ“' if key_concerns else 'âœ—'}\")\n",
    "        print(f\"  Dimensional evaluations: {len(dimensional_evaluations) if 'dimensional_evaluations' in locals() else 0}/11\")\n",
    "        final_report = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Updated Architecture Summary\n",
    "\n",
    "### Multi-Agent System Architecture:\n",
    "\n",
    "1. **Agent 1 (Extraction)**: Extract substantive content from PDF\n",
    "   - Temperature: 0.3 (focused extraction)\n",
    "   - Focus: Business opportunity analysis, eliminating noise\n",
    "   - Auto-saves checkpoint after completion\n",
    "   - Output: Structured market intelligence\n",
    "\n",
    "2. **Agent 2 (Idea Generation)**: Create innovative business ideas\n",
    "   - Temperature: 0.8 (creative generation)\n",
    "   - Loads from Agent 1 checkpoint (no re-extraction!)\n",
    "   - Auto-saves checkpoint after completion\n",
    "   - Output: Detailed business ideas\n",
    "\n",
    "3. **Agent 3 (Dimensional Evaluation)**: 11 specialized sub-agents\n",
    "   - Temperature: 0.4 (consistent evaluation)\n",
    "   - Each sub-agent evaluates one dimension (1-10 scale)\n",
    "   - Each saves its own checkpoint (agent3_1 through agent3_11)\n",
    "   - All load from Agent 2 checkpoint\n",
    "   - **11 Dimensions:**\n",
    "     1. Market Potential\n",
    "     2. Differentiated Approach and Positioning\n",
    "     3. Sustainable Competitive Advantage\n",
    "     4. Differentiating Element\n",
    "     5. Technical Feasibility\n",
    "     6. Affordable & Rapid Implementation\n",
    "     7. AI Enablement for Core Value\n",
    "     8. Barrier to Entry\n",
    "     9. Scalable Technology & Operations\n",
    "     10. Product-Focused Output\n",
    "     11. Subscription-Based Platform Access\n",
    "\n",
    "4. **Agent 4 (Specialized Synthesis)**: 3 specialized sub-agents\n",
    "   - Temperature: 0.4-0.5 (focused synthesis)\n",
    "   - Each sub-agent generates one specific component\n",
    "   - Each saves its own checkpoint (agent4_1, agent4_2, agent4_3)\n",
    "   - **Sub-agents:**\n",
    "     - **Agent 4.1**: Business Idea Summary (2-4 sentences)\n",
    "     - **Agent 4.2**: Key Strengths (top 3 with justifications)\n",
    "     - **Agent 4.3**: Key Concerns (top 3 with risk analysis)\n",
    "\n",
    "5. **Agent 5 (Final Consolidation)**: Generate comprehensive JSON report\n",
    "   - Temperature: 0.5 (balanced)\n",
    "   - Loads all checkpoints (agent3_1-3_11, agent4_1-4_3)\n",
    "   - Calculates weighted overall score\n",
    "   - Generates recommendation rationale\n",
    "   - Outputs final JSON report\n",
    "   - Saves to checkpoint and results file\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **Provider-Agnostic**: Switch between Groq, Ollama, Anthropic, OpenAI\n",
    "- **Smart Checkpointing**: Resume from any agent, skip completed work\n",
    "- **17 Total Checkpoints**: agent1, agent2, agent3_1-3_11, agent4_1-4_3, agent5\n",
    "- **Modular Synthesis**: Separate agents for each output component ensures quality\n",
    "- **Weighted Scoring**: Configurable weights for each dimension\n",
    "- **Structured Output**: JSON format for easy integration\n",
    "- **Focused Agents**: Each agent has a single, clear responsibility\n",
    "\n",
    "### Pipeline Flow:\n",
    "\n",
    "```\n",
    "PDF â†’ Agent 1 (Extract)\n",
    "    â†’ Agent 2 (Generate Ideas)\n",
    "    â†’ Agent 3.1-3.11 (Dimensional Evaluations)\n",
    "    â†’ Agent 4.1 (Summary)\n",
    "    â†’ Agent 4.2 (Strengths)\n",
    "    â†’ Agent 4.3 (Concerns)\n",
    "    â†’ Agent 5 (Consolidate & Report)\n",
    "    â†’ Final JSON Report\n",
    "```\n",
    "\n",
    "### Why This Architecture:\n",
    "\n",
    "- **Modularity**: Each component can be refined independently\n",
    "- **Quality Control**: Dedicated agents ensure each output is well-generated\n",
    "- **Debugging**: Easy to identify which component failed\n",
    "- **Flexibility**: Can re-run specific agents without full pipeline\n",
    "- **Checkpoint Efficiency**: Test different prompts instantly using cached data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
